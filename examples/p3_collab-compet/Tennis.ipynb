{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11601e438>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal Dependencies\n",
    "As described in the report and as in the previous project, we are using a custom library called rl_library which needs to be installed AFTER the unityagents as been setup.\n",
    "\n",
    "For this execute the following steps from a terminal in the correct virtual environment at the root of the repository:\n",
    "\n",
    "\n",
    " - `pip install -r requirements.txt`\n",
    " - `pip install . `\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "from rl_library.agents.maddpg_agent import MADDPGAgent\n",
    "from rl_library.agents.models.bodies import SimpleNeuralNetBody\n",
    "from rl_library.agents.models.heads import SimpleNeuralNetHead, DeepNeuralNetHeadCritic\n",
    "from rl_library.monitors.unity_monitor import UnityMonitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"./results/Tennis_MADDPG_{pd.Timestamp.utcnow().value}\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s : %(message)s')\n",
    "\n",
    "handler = logging.FileHandler(f\"{save_path}/logs_p3_{pd.Timestamp.utcnow().value}.log\")\n",
    "handler.setLevel(logging.DEBUG)\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 2500\n",
    "config = dict(\n",
    "    # Environment parameters\n",
    "    env_name=\"Tennis\",\n",
    "    n_episodes=n_episodes,\n",
    "    length_episode=1500,\n",
    "    save_every=500,\n",
    "    save_path=save_path,\n",
    "    mode=\"train\",  # \"train\" or \"test\"\n",
    "    evaluate_every=5000,  # Number of training episodes before 1 evaluation episode\n",
    "    eps_decay=1,  # Epsilon decay rate\n",
    "\n",
    "    # Agent Parameters\n",
    "    agent=\"DDPG\",\n",
    "    hidden_layers_actor=(256, 128),  # (50, 50, 15),  # (200, 150),  #\n",
    "    hidden_layers_critic_body=(256,),  # (50, 50,),  #\n",
    "    hidden_layers_critic_head=(128,),  # (50,),   # (300,)\n",
    "    func_critic_body=\"F.leaky_relu\",  #\n",
    "    func_critic_head=\"F.leaky_relu\",  #\n",
    "    func_actor_body=\"F.leaky_relu\",  #\n",
    "    lr_scheduler=None,\n",
    "    # lr_scheduler={'scheduler_type': \"multistep\",  # \"step\", \"exp\" or \"decay\", \"multistep\"\n",
    "    #               'gamma': 0.75,  # 0.99999,\n",
    "    #               'step_size': 1,\n",
    "    #               'milestones': [30 * 1000 * i for i in range(1, 6)],\n",
    "    #               'max_epochs': n_episodes},\n",
    "\n",
    "    TAU=1e-3,  # for soft update of target parameters\n",
    "    BUFFER_SIZE=int(3e4),  # replay buffer size\n",
    "    BATCH_SIZE=128,  # minibatch size\n",
    "    GAMMA=0.99,  # discount factor\n",
    "    LR_ACTOR=1e-4,  # learning rate of the actor\n",
    "    LR_CRITIC=1e-4,  # learning rate of the critic\n",
    "    WEIGHT_DECAY=0,  # L2 weight decay\n",
    "    UPDATE_EVERY=1,  # Number of actions before making a learning step\n",
    "    N_CONSECUTIVE_LEARNING_STEPS=2,\n",
    "    action_noise=\"OU\",  #\n",
    "    action_noise_scale=1,\n",
    "    weights_noise=None,  #\n",
    "    state_normalizer=\"BatchNorm\",  # \"RunningMeanStd\" or \"BatchNorm\"\n",
    "    warmup=1e3,  # Number of random actions to start with as a warm-up\n",
    "    start_time=str(pd.Timestamp.utcnow()),\n",
    "    random_seed=seed,\n",
    "    threshold=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=f'./{config[\"env_name\"]}')  # mac OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -7.38993645 -1.5\n",
      " -0.          0.          6.83172083  5.99607611 -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "config[\"n_agents\"] = num_agents\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space\n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])\n",
    "config.update(dict(action_size=action_size, state_size=state_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unity Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  7.90150833e+00 -1.00000000e+00\n",
      "  1.25147629e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -5.22214413e-01]\n"
     ]
    }
   ],
   "source": [
    "monitor = UnityMonitor(env=env, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor and Critic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rllib.models:Initialized SimpleNeuralNetHead with body : ModuleList(\n",
      "  (0): Linear(in_features=33, out_features=200, bias=True)\n",
      "  (1): Linear(in_features=200, out_features=150, bias=True)\n",
      ") and head Linear(in_features=150, out_features=4, bias=True)\n",
      "INFO:rllib.models:state_dict= OrderedDict([('body.layers.0.weight', tensor([[ 0.0069,  0.0236,  0.0656,  ...,  0.0022,  0.0687,  0.0359],\n",
      "        [ 0.0332, -0.0127, -0.0178,  ...,  0.0119,  0.0394,  0.0308],\n",
      "        [ 0.0394, -0.0615,  0.0259,  ..., -0.0399,  0.0312,  0.0176],\n",
      "        ...,\n",
      "        [ 0.0686, -0.0601, -0.0615,  ..., -0.0107,  0.0513, -0.0177],\n",
      "        [-0.0322, -0.0090,  0.0421,  ..., -0.0328,  0.0604,  0.0343],\n",
      "        [-0.0611,  0.0538,  0.0468,  ...,  0.0646, -0.0550,  0.0647]])), ('body.layers.0.bias', tensor([ 0.1632, -0.0778, -0.0771, -0.0725, -0.1326,  0.1624, -0.0983, -0.0783,\n",
      "        -0.0527,  0.1465,  0.0812,  0.0641, -0.0458,  0.0880,  0.0316,  0.1387,\n",
      "         0.0386,  0.1278,  0.1201,  0.0304, -0.1668,  0.0354, -0.1313,  0.0299,\n",
      "        -0.0195,  0.1385, -0.1250, -0.1455,  0.0776,  0.1149, -0.0379,  0.0471,\n",
      "         0.1397,  0.0173, -0.0487,  0.1007,  0.1569, -0.0295,  0.1181,  0.0145,\n",
      "        -0.0364, -0.0152, -0.1690,  0.0835, -0.0947, -0.1483, -0.0241, -0.0709,\n",
      "        -0.1108, -0.0366, -0.0184,  0.0529,  0.0239, -0.0233,  0.0383, -0.1126,\n",
      "         0.1473,  0.0852,  0.1101, -0.1553,  0.1188,  0.0308, -0.1682,  0.1653,\n",
      "        -0.0036,  0.0334,  0.1440,  0.1123,  0.1549, -0.1625,  0.1721,  0.0424,\n",
      "         0.0023, -0.1368, -0.0936,  0.1690,  0.1294,  0.1357, -0.0146, -0.0970,\n",
      "         0.0406, -0.0829, -0.1133,  0.0562,  0.1365, -0.1335, -0.1539,  0.0235,\n",
      "        -0.0613, -0.0931, -0.0356, -0.0101, -0.0483,  0.1289,  0.0965,  0.0548,\n",
      "        -0.0558, -0.0155,  0.1129,  0.0144, -0.1679,  0.0165,  0.0912, -0.0447,\n",
      "        -0.0325, -0.0236,  0.1070,  0.1437, -0.1366,  0.1147,  0.0713,  0.0609,\n",
      "        -0.0989, -0.0994,  0.1729,  0.0445, -0.0387, -0.0353,  0.1165, -0.0434,\n",
      "         0.1176, -0.0494,  0.0411,  0.0459, -0.0892,  0.0043,  0.0348, -0.1702,\n",
      "        -0.0343,  0.0166,  0.1434,  0.0385, -0.1480, -0.0510,  0.1723, -0.0227,\n",
      "         0.1313,  0.0200,  0.1142, -0.0748,  0.1710,  0.0367, -0.0356,  0.1338,\n",
      "         0.0858, -0.1170, -0.0125,  0.1248,  0.0434, -0.0551, -0.1133, -0.1219,\n",
      "         0.0968,  0.0788, -0.1543, -0.0357,  0.0441, -0.1540,  0.1500, -0.0186,\n",
      "        -0.0707,  0.0194,  0.0629,  0.0387,  0.1651,  0.0980, -0.0169,  0.0296,\n",
      "         0.0422, -0.0690, -0.1492, -0.0185, -0.0663, -0.1644,  0.0621, -0.0730,\n",
      "         0.1667,  0.0623,  0.0741,  0.0507,  0.0679,  0.1115,  0.1279, -0.0095,\n",
      "        -0.0493,  0.0472, -0.0785, -0.0088,  0.0508,  0.0778, -0.1684,  0.0674,\n",
      "        -0.0674, -0.1226, -0.0741, -0.0038,  0.0857, -0.1550,  0.0473,  0.1568])), ('body.layers.1.weight', tensor([[-0.0389, -0.0004, -0.0558,  ..., -0.0543, -0.0442,  0.0672],\n",
      "        [-0.0558, -0.0693,  0.0142,  ...,  0.0692, -0.0509,  0.0418],\n",
      "        [-0.0390,  0.0561, -0.0344,  ..., -0.0315,  0.0358,  0.0806],\n",
      "        ...,\n",
      "        [ 0.0204,  0.0186,  0.0342,  ..., -0.0476,  0.0596, -0.0774],\n",
      "        [ 0.0101, -0.0790, -0.0237,  ...,  0.0532, -0.0660,  0.0624],\n",
      "        [ 0.0315,  0.0186, -0.0141,  ...,  0.0676, -0.0109,  0.0461]])), ('body.layers.1.bias', tensor([-0.0319, -0.0065, -0.0296,  0.0527, -0.0083, -0.0349,  0.0562,  0.0358,\n",
      "        -0.0457, -0.0184,  0.0658, -0.0469, -0.0584,  0.0218, -0.0211, -0.0395,\n",
      "         0.0068, -0.0585, -0.0401, -0.0157, -0.0233,  0.0233,  0.0133, -0.0129,\n",
      "        -0.0438,  0.0650,  0.0513,  0.0274,  0.0440,  0.0518,  0.0488, -0.0381,\n",
      "         0.0174, -0.0202,  0.0336,  0.0312, -0.0046,  0.0700, -0.0038,  0.0103,\n",
      "        -0.0363,  0.0585,  0.0428,  0.0309,  0.0614,  0.0034,  0.0374, -0.0325,\n",
      "        -0.0138,  0.0039,  0.0556,  0.0459, -0.0400, -0.0466,  0.0383, -0.0477,\n",
      "         0.0688,  0.0706, -0.0608, -0.0348,  0.0468,  0.0003, -0.0528,  0.0572,\n",
      "        -0.0257, -0.0543,  0.0703, -0.0613, -0.0159,  0.0255, -0.0013, -0.0688,\n",
      "         0.0168,  0.0279, -0.0244,  0.0670,  0.0572,  0.0401, -0.0475, -0.0463,\n",
      "         0.0590,  0.0431, -0.0157,  0.0647,  0.0654, -0.0034,  0.0654, -0.0173,\n",
      "         0.0324,  0.0602,  0.0209,  0.0008, -0.0386, -0.0159, -0.0482, -0.0563,\n",
      "        -0.0408,  0.0009, -0.0439, -0.0422, -0.0377, -0.0463, -0.0558,  0.0080,\n",
      "         0.0581,  0.0662,  0.0683, -0.0147, -0.0693, -0.0220, -0.0147, -0.0333,\n",
      "         0.0273,  0.0685, -0.0275,  0.0668, -0.0707, -0.0355,  0.0488,  0.0210,\n",
      "         0.0435, -0.0503, -0.0328, -0.0143,  0.0659, -0.0701,  0.0223,  0.0478,\n",
      "         0.0345,  0.0420, -0.0050,  0.0147, -0.0002, -0.0378,  0.0444, -0.0693,\n",
      "        -0.0098,  0.0588, -0.0524, -0.0257, -0.0041,  0.0699,  0.0566,  0.0400,\n",
      "         0.0261, -0.0089,  0.0616, -0.0264,  0.0382, -0.0439])), ('head.weight', tensor([[ 1.7935e-03,  2.8280e-03, -2.5177e-03, -1.7050e-03,  1.4146e-03,\n",
      "         -1.8496e-03, -2.3041e-03,  1.0930e-03, -1.5693e-03,  2.9740e-03,\n",
      "         -9.4225e-04, -2.3995e-03, -1.5976e-03,  1.3900e-04,  2.6509e-03,\n",
      "         -1.8068e-04, -2.1692e-03, -2.8085e-03,  2.9667e-03, -1.3372e-03,\n",
      "          2.2130e-03, -4.8218e-04,  1.0592e-03, -7.9612e-05,  2.4411e-03,\n",
      "         -2.9305e-03,  1.4180e-03, -2.4095e-03, -8.1861e-04, -2.6852e-03,\n",
      "          1.0264e-03, -1.9085e-03,  2.4367e-03, -1.5442e-03, -2.5128e-03,\n",
      "         -2.5772e-03,  1.3803e-03, -1.5667e-03,  2.6378e-03,  2.1180e-03,\n",
      "          1.6757e-03,  1.3997e-03, -1.4129e-03, -2.7749e-03,  2.6020e-03,\n",
      "         -1.7497e-03,  2.2813e-03, -2.9560e-03, -7.8752e-04, -8.9381e-04,\n",
      "         -1.8992e-03,  1.4068e-03, -4.2914e-04, -7.2396e-04, -2.7463e-03,\n",
      "         -7.6358e-04, -1.3867e-03, -1.2304e-04,  2.9978e-03, -2.9134e-03,\n",
      "         -1.9523e-03,  4.7509e-04, -2.2018e-03, -1.0286e-03, -8.1882e-05,\n",
      "         -7.7629e-05, -2.6651e-04,  3.0050e-05,  4.3759e-04, -1.7119e-03,\n",
      "          1.3382e-03,  1.6110e-03, -2.2740e-03,  1.7359e-03, -1.8819e-03,\n",
      "         -7.2121e-04, -2.6921e-03, -8.0780e-04, -5.6405e-04, -2.7043e-03,\n",
      "         -2.0580e-03, -1.9396e-04,  2.6926e-03, -2.0691e-03,  1.7810e-03,\n",
      "         -6.7355e-04,  8.6459e-04, -5.7784e-04,  2.7064e-03, -2.7557e-03,\n",
      "          5.8277e-04, -2.7370e-03, -1.5989e-04, -1.8568e-03,  1.2897e-03,\n",
      "         -4.5162e-04,  2.1687e-03, -1.5753e-03,  1.8426e-03,  7.8810e-04,\n",
      "         -1.2197e-03,  4.6403e-04,  1.7390e-03, -6.4759e-04,  1.7585e-03,\n",
      "         -5.1656e-04,  1.8781e-03,  2.6357e-03,  5.7945e-04,  2.1709e-03,\n",
      "          1.4768e-03,  8.5124e-05,  2.6720e-03, -2.3313e-03,  9.4104e-04,\n",
      "         -7.7220e-04, -2.1146e-03, -1.8372e-03, -2.4359e-03, -1.9525e-04,\n",
      "         -2.2908e-03, -1.0130e-03, -2.6516e-03,  3.2705e-04, -1.3804e-03,\n",
      "         -1.9673e-03, -1.5090e-03, -1.1387e-03, -1.8216e-03, -1.8708e-03,\n",
      "         -1.8795e-03,  2.6628e-03,  7.2774e-04,  1.3693e-03, -2.8622e-03,\n",
      "          9.1512e-04, -6.5188e-04, -1.6488e-03, -4.0340e-04,  1.4053e-03,\n",
      "          1.5026e-04,  2.7855e-03, -2.7574e-03, -2.3468e-03,  4.2841e-04,\n",
      "         -9.9738e-04,  2.9845e-04, -2.9735e-03, -1.5817e-03, -5.9394e-05],\n",
      "        [ 1.9472e-03, -2.8019e-03,  8.4975e-04, -4.3980e-04,  1.8385e-03,\n",
      "          3.7625e-04,  1.9804e-03,  1.7418e-03,  1.2465e-03,  3.3654e-04,\n",
      "          2.1752e-03, -2.9881e-03, -2.9707e-03, -5.2040e-04, -1.8704e-03,\n",
      "          2.8350e-03, -7.4967e-04,  2.5706e-04, -1.1427e-03, -7.2517e-05,\n",
      "          1.4062e-03, -2.0297e-03,  2.2881e-03,  2.0524e-03, -1.5411e-04,\n",
      "         -2.9469e-03,  1.4438e-03, -4.1408e-05, -2.1785e-03,  2.1440e-03,\n",
      "         -9.0375e-04,  8.5130e-04, -2.5131e-03,  2.4161e-03,  2.6661e-03,\n",
      "          1.3088e-03, -1.1189e-03, -1.7005e-03, -7.4850e-04,  1.2065e-03,\n",
      "         -1.1377e-03, -4.9187e-04,  2.2271e-03,  1.4410e-03, -2.5744e-03,\n",
      "          1.1744e-03, -1.3336e-03,  7.1315e-04,  1.8256e-03, -9.1192e-04,\n",
      "          2.7550e-04,  1.8547e-03,  3.1781e-04,  2.4532e-03, -2.3604e-03,\n",
      "         -2.9289e-03, -1.3270e-03, -1.4775e-03,  2.9499e-03,  7.1196e-04,\n",
      "         -1.6290e-04,  9.4694e-04,  1.4735e-03,  1.8883e-03,  3.6277e-05,\n",
      "         -2.8949e-03,  2.4801e-03,  1.3148e-03, -2.6715e-03,  2.8440e-03,\n",
      "          1.5534e-03, -4.9041e-04, -1.7672e-03, -3.8369e-04, -2.8149e-03,\n",
      "          3.4256e-04,  2.2785e-03,  5.4833e-04,  1.0368e-03,  5.0930e-04,\n",
      "         -2.6557e-04, -1.0962e-03, -2.7985e-03,  1.0447e-03,  2.2467e-03,\n",
      "         -2.8347e-04,  1.7405e-03, -1.0417e-03, -7.4973e-04,  2.9943e-03,\n",
      "         -1.2831e-03, -1.9219e-03,  2.6647e-03,  2.2338e-03, -2.6411e-03,\n",
      "         -2.2349e-03,  2.2580e-03,  2.1009e-04,  2.0767e-03, -2.6590e-03,\n",
      "         -1.3875e-03, -2.3444e-03,  1.9883e-03,  2.4004e-03,  1.1180e-03,\n",
      "          1.7405e-03,  1.1285e-03,  2.1969e-03, -1.8632e-03,  2.2253e-03,\n",
      "          6.1952e-04, -2.9473e-03,  5.5736e-04, -2.6081e-03, -2.5031e-03,\n",
      "         -5.9639e-04, -1.5184e-03, -2.2240e-03,  1.4333e-03,  4.2313e-04,\n",
      "         -1.6588e-04, -1.8927e-03,  1.9351e-03, -2.4350e-03,  1.8329e-03,\n",
      "         -2.7555e-03, -2.7339e-03,  2.5817e-05, -6.3379e-04,  2.3206e-04,\n",
      "          2.2193e-03,  1.7347e-04, -5.1736e-04, -2.9839e-03, -1.4472e-03,\n",
      "         -1.6977e-03, -8.3968e-04, -2.0885e-03,  1.9886e-03,  1.6417e-03,\n",
      "         -2.9991e-03,  2.7118e-03,  1.8655e-04, -2.5085e-03, -1.1161e-03,\n",
      "         -2.2938e-03,  1.0614e-03,  2.8015e-03,  2.0978e-03, -2.8928e-04],\n",
      "        [-2.9285e-03, -2.3146e-03, -1.7264e-03,  2.3841e-03,  1.3524e-03,\n",
      "         -4.7060e-04,  1.0978e-03, -2.9542e-03, -1.6120e-03, -1.9749e-03,\n",
      "         -2.9407e-03,  1.7020e-03, -2.7556e-03,  2.7275e-03, -2.8212e-03,\n",
      "          2.7729e-03,  5.0351e-04,  1.5196e-03,  1.0874e-03, -1.3096e-03,\n",
      "          3.6640e-04, -2.7036e-04, -4.4557e-04, -2.5242e-03, -4.9447e-04,\n",
      "          2.0538e-04, -2.3433e-04, -9.4131e-04, -2.4306e-03, -2.9250e-03,\n",
      "          1.5888e-03, -1.9801e-04,  1.8406e-03, -2.8001e-03,  1.3718e-03,\n",
      "          2.0172e-03,  2.9145e-03,  9.9400e-04,  1.3167e-03, -2.5345e-03,\n",
      "          2.6270e-03,  1.9729e-03, -1.5132e-03, -2.5441e-03, -2.0505e-03,\n",
      "          1.2295e-03, -9.9956e-04,  2.3867e-03, -2.5887e-04,  1.2252e-03,\n",
      "          1.4343e-03, -1.1468e-03,  1.1591e-04,  3.4771e-04, -1.3121e-03,\n",
      "          4.4636e-04, -1.1167e-03,  1.3004e-03, -1.1633e-03,  2.3723e-03,\n",
      "         -2.5299e-04,  1.4635e-03,  2.4510e-03, -2.1190e-03,  4.7311e-04,\n",
      "         -1.4323e-03,  1.4227e-03, -2.6452e-03, -6.5117e-04, -1.9950e-04,\n",
      "          1.1293e-04, -2.9388e-03, -2.1434e-04, -1.1508e-03, -7.5162e-04,\n",
      "         -2.3626e-03, -3.6327e-04, -2.6866e-03, -2.5947e-03,  1.0098e-03,\n",
      "          2.6136e-03, -2.3439e-03, -2.5057e-03,  4.8637e-04, -1.9389e-03,\n",
      "         -2.2052e-03, -1.7646e-03, -6.9422e-04, -4.0126e-05,  2.5197e-03,\n",
      "         -2.8899e-03, -2.1518e-03,  6.8143e-04,  8.7256e-04, -2.8159e-03,\n",
      "         -2.6616e-03, -2.4853e-03, -4.2906e-04,  1.4877e-03, -1.1931e-03,\n",
      "          6.9198e-04,  8.7493e-04,  3.3391e-04,  1.4054e-03,  2.5919e-03,\n",
      "         -9.1550e-04,  1.1945e-03,  2.3563e-03,  8.8879e-04, -1.3584e-03,\n",
      "         -2.4488e-03,  2.5563e-03, -2.4878e-03,  1.2052e-03,  2.1145e-03,\n",
      "          5.5436e-05,  7.2921e-04,  2.2088e-04, -2.7429e-03,  6.4909e-04,\n",
      "          1.5934e-03,  2.6843e-03, -1.0726e-03, -1.1111e-03,  1.8740e-03,\n",
      "         -1.6555e-03,  2.6699e-04,  2.4801e-03, -8.8992e-04,  1.7793e-03,\n",
      "         -4.0264e-04, -1.6223e-03, -5.6341e-04, -1.0713e-04,  1.2227e-03,\n",
      "         -1.6197e-03,  2.9506e-03,  1.4402e-03, -2.8839e-03, -2.8012e-03,\n",
      "          4.6998e-04,  2.9324e-04, -1.7743e-03, -2.9774e-03, -1.1234e-03,\n",
      "         -2.0097e-03,  1.6122e-03,  2.4470e-04,  1.8894e-06, -2.2687e-03],\n",
      "        [ 2.1624e-03, -1.7002e-03,  3.7044e-04, -2.9128e-03, -2.9335e-03,\n",
      "         -4.8838e-04,  9.2950e-04, -7.7569e-05, -1.0130e-03,  2.0509e-03,\n",
      "          1.8920e-03, -2.5689e-03,  1.0198e-04, -1.4444e-03,  2.0450e-03,\n",
      "          6.5266e-04,  1.0069e-03,  2.1192e-03,  1.8374e-03,  2.2917e-03,\n",
      "          1.4439e-04, -2.3455e-03,  3.3081e-05, -2.2146e-03, -1.6116e-03,\n",
      "         -1.0324e-03,  2.0557e-04, -1.8033e-03, -9.7598e-04,  2.7767e-03,\n",
      "          2.5682e-03, -2.4847e-04,  6.4351e-04, -2.9722e-03, -1.5509e-03,\n",
      "         -1.7964e-03, -2.0577e-03,  1.7572e-03, -3.5997e-04, -4.3248e-04,\n",
      "         -2.4526e-03,  1.3989e-03,  2.0783e-03, -1.3455e-03, -2.9817e-03,\n",
      "          2.8245e-04, -2.6062e-05,  7.3660e-04, -5.8197e-04, -2.8023e-03,\n",
      "         -7.3985e-04,  2.6143e-04, -2.9696e-03, -2.3374e-03,  2.9980e-03,\n",
      "         -2.9642e-03,  1.5478e-03, -2.3424e-03,  2.9864e-03, -2.6620e-03,\n",
      "         -7.8084e-04, -3.7567e-04,  2.4982e-03, -7.5183e-04, -1.7520e-03,\n",
      "          1.6724e-03, -2.3592e-03,  2.5786e-03,  2.3818e-03,  1.4590e-03,\n",
      "          2.0211e-04,  2.0946e-03,  1.9254e-03,  9.8302e-04, -6.5772e-05,\n",
      "         -1.3348e-03,  4.6068e-04,  3.0177e-06, -1.5812e-03, -4.9117e-04,\n",
      "          2.6079e-03,  2.3072e-03,  1.6685e-03,  2.8964e-03, -1.2478e-03,\n",
      "          1.4333e-03,  1.5876e-04,  2.8793e-03,  3.1102e-04, -1.0556e-03,\n",
      "          2.7069e-03, -9.0307e-04, -1.4818e-03, -9.3847e-04,  1.9407e-03,\n",
      "         -4.4411e-04, -2.3523e-03, -2.7658e-03,  6.5393e-05, -2.1907e-03,\n",
      "          4.4995e-05, -8.2158e-04, -2.4733e-04,  2.4158e-03,  2.3315e-04,\n",
      "          1.1000e-04,  2.3367e-03, -1.4736e-04, -2.3957e-03, -1.6746e-03,\n",
      "          1.2153e-03, -3.0810e-04,  2.1623e-03,  1.4630e-03,  1.2494e-03,\n",
      "          2.8324e-03,  2.4694e-03,  1.0135e-03, -6.1475e-04, -2.0816e-03,\n",
      "          2.5872e-03, -2.6123e-03, -7.4222e-04, -2.0490e-03, -1.7517e-04,\n",
      "          1.2902e-03, -9.0808e-04,  9.8754e-04, -4.3625e-04,  1.2426e-03,\n",
      "         -4.9095e-04, -1.4841e-03, -2.1397e-03,  1.0192e-03,  5.1187e-04,\n",
      "         -1.6778e-03, -9.6452e-04, -2.5631e-03, -2.1202e-03, -2.8980e-03,\n",
      "          2.9257e-03, -2.1447e-03,  1.3011e-03, -2.5384e-03,  7.1646e-04,\n",
      "          1.4457e-03, -2.7896e-03, -2.8125e-03,  4.8421e-04,  1.1616e-03]])), ('head.bias', tensor([ 6.8624e-02, -8.7956e-03,  7.1831e-02,  7.1265e-05]))])\n",
      "INFO:rllib.models:Initialized SimpleNeuralNetHead with body : ModuleList(\n",
      "  (0): Linear(in_features=33, out_features=200, bias=True)\n",
      "  (1): Linear(in_features=200, out_features=150, bias=True)\n",
      ") and head Linear(in_features=150, out_features=4, bias=True)\n",
      "INFO:rllib.models:state_dict= OrderedDict([('body.layers.0.weight', tensor([[-0.0289,  0.0285, -0.0238,  ...,  0.0634, -0.0549,  0.0473],\n",
      "        [-0.0586, -0.0493,  0.0679,  ...,  0.0014, -0.0119, -0.0104],\n",
      "        [-0.0392, -0.0300,  0.0552,  ..., -0.0311, -0.0150, -0.0115],\n",
      "        ...,\n",
      "        [ 0.0248, -0.0296,  0.0376,  ..., -0.0469, -0.0043,  0.0480],\n",
      "        [ 0.0182,  0.0685, -0.0453,  ..., -0.0488,  0.0606, -0.0243],\n",
      "        [ 0.0401, -0.0551, -0.0440,  ...,  0.0312, -0.0467,  0.0116]])), ('body.layers.0.bias', tensor([ 0.0682,  0.0751,  0.1120,  0.0074, -0.1022,  0.0554,  0.0007, -0.1266,\n",
      "        -0.0342, -0.1410, -0.0395,  0.1268,  0.0886,  0.0249, -0.0366, -0.0667,\n",
      "        -0.1547,  0.1382,  0.1331,  0.0238, -0.1414,  0.0418, -0.0201, -0.0227,\n",
      "        -0.0761, -0.1288,  0.0926,  0.1127, -0.1470,  0.1343, -0.0085, -0.1585,\n",
      "         0.0239,  0.0841, -0.1280, -0.1365, -0.0163, -0.1046, -0.1044,  0.0527,\n",
      "        -0.1511,  0.1253, -0.1002,  0.1553,  0.1206,  0.0315, -0.1554, -0.1264,\n",
      "         0.0120, -0.1706,  0.1078, -0.1554, -0.1144, -0.1054, -0.1149,  0.1567,\n",
      "        -0.1428,  0.0316,  0.1603, -0.1071,  0.0269, -0.1251, -0.0874, -0.1028,\n",
      "         0.0093,  0.1224, -0.1323, -0.1001, -0.1257,  0.0111,  0.0310,  0.0276,\n",
      "        -0.0580, -0.0662,  0.0617, -0.1354,  0.1703,  0.0817, -0.1648, -0.0577,\n",
      "        -0.0766,  0.0749, -0.1583,  0.1402,  0.1032, -0.0929, -0.0607, -0.0901,\n",
      "        -0.0963, -0.1492,  0.0569,  0.0518, -0.1726, -0.1657, -0.0062, -0.0155,\n",
      "        -0.0409,  0.1660, -0.0992, -0.0764, -0.0149, -0.0739,  0.0099, -0.0123,\n",
      "         0.1356, -0.0333, -0.0760, -0.1424, -0.1441, -0.0635,  0.0878, -0.0023,\n",
      "        -0.0140,  0.0992,  0.0798, -0.0699, -0.0017,  0.0377, -0.0976, -0.0158,\n",
      "         0.0499, -0.0689,  0.0442, -0.0647,  0.1570, -0.1577,  0.1630, -0.0044,\n",
      "         0.0599, -0.0745,  0.1421, -0.0423, -0.1197,  0.1145, -0.0213, -0.0221,\n",
      "         0.0963,  0.0312,  0.1295,  0.0412,  0.1339, -0.0493,  0.0126, -0.1112,\n",
      "         0.1490, -0.1710, -0.1432, -0.0053, -0.1622, -0.0080, -0.0892,  0.1654,\n",
      "        -0.1381,  0.0826,  0.0303, -0.1087,  0.1734,  0.0597,  0.1392, -0.1519,\n",
      "        -0.1356,  0.1231, -0.0352, -0.1598,  0.0656,  0.1358, -0.0301,  0.1273,\n",
      "        -0.0170, -0.0072, -0.0649, -0.1119, -0.1519,  0.0038, -0.1575,  0.0277,\n",
      "        -0.0505, -0.1064, -0.0161, -0.1300, -0.1282,  0.1085, -0.0228,  0.0344,\n",
      "         0.0190,  0.0334,  0.1662,  0.1189,  0.1435,  0.1576,  0.0392,  0.0248,\n",
      "         0.0204, -0.0878, -0.0131,  0.0009, -0.1243, -0.0554,  0.0841,  0.0065])), ('body.layers.1.weight', tensor([[ 0.0352, -0.0738,  0.0327,  ..., -0.0575,  0.0285, -0.0530],\n",
      "        [ 0.0039,  0.0769,  0.0676,  ...,  0.0068, -0.0204,  0.0074],\n",
      "        [-0.0410,  0.0385, -0.0244,  ...,  0.0035,  0.0250, -0.0425],\n",
      "        ...,\n",
      "        [-0.0195,  0.0549, -0.0654,  ..., -0.0643, -0.0104, -0.0191],\n",
      "        [-0.0540, -0.0505,  0.0663,  ..., -0.0636, -0.0257,  0.0470],\n",
      "        [-0.0252, -0.0450,  0.0496,  ...,  0.0319,  0.0383, -0.0585]])), ('body.layers.1.bias', tensor([-0.0117,  0.0059, -0.0406,  0.0182, -0.0691,  0.0681,  0.0650,  0.0692,\n",
      "        -0.0140, -0.0610, -0.0109,  0.0297,  0.0537,  0.0582,  0.0398,  0.0539,\n",
      "        -0.0303, -0.0167,  0.0223,  0.0602, -0.0307,  0.0666, -0.0187,  0.0655,\n",
      "         0.0193, -0.0015, -0.0174,  0.0432,  0.0631,  0.0702,  0.0256, -0.0547,\n",
      "         0.0510,  0.0265,  0.0098, -0.0549,  0.0525, -0.0577,  0.0562, -0.0092,\n",
      "        -0.0252, -0.0297, -0.0463, -0.0576, -0.0031, -0.0378, -0.0299,  0.0567,\n",
      "         0.0096,  0.0466,  0.0523,  0.0069,  0.0284, -0.0394, -0.0115, -0.0441,\n",
      "        -0.0465,  0.0550, -0.0652,  0.0182,  0.0706,  0.0583,  0.0296,  0.0472,\n",
      "         0.0177,  0.0494,  0.0079, -0.0308,  0.0335,  0.0405, -0.0013,  0.0354,\n",
      "        -0.0044,  0.0134, -0.0449,  0.0644, -0.0479,  0.0417, -0.0660,  0.0188,\n",
      "        -0.0122, -0.0553,  0.0600, -0.0494, -0.0377,  0.0407,  0.0683, -0.0191,\n",
      "        -0.0588, -0.0386, -0.0401, -0.0534,  0.0567,  0.0524, -0.0604,  0.0442,\n",
      "        -0.0277, -0.0094, -0.0431,  0.0449, -0.0199,  0.0435,  0.0079,  0.0367,\n",
      "         0.0552, -0.0204, -0.0564,  0.0573,  0.0356, -0.0665,  0.0343,  0.0220,\n",
      "        -0.0123, -0.0045, -0.0312,  0.0107,  0.0459, -0.0238, -0.0145, -0.0106,\n",
      "         0.0441, -0.0108,  0.0230, -0.0491,  0.0521, -0.0073, -0.0235,  0.0302,\n",
      "         0.0680, -0.0400,  0.0326, -0.0242, -0.0196, -0.0668,  0.0181,  0.0671,\n",
      "        -0.0649,  0.0188,  0.0393, -0.0447, -0.0460, -0.0684,  0.0091, -0.0088,\n",
      "        -0.0454,  0.0550,  0.0466,  0.0503, -0.0468, -0.0662])), ('head.weight', tensor([[ 1.1844e-03, -6.8600e-04, -1.9503e-03,  2.2637e-03,  2.1332e-03,\n",
      "          2.1426e-03, -2.7848e-03,  1.5510e-03,  2.4925e-03,  1.0103e-03,\n",
      "          1.2490e-03, -9.6018e-05,  1.0148e-03, -2.4769e-03, -2.9344e-03,\n",
      "         -1.5459e-03,  6.2515e-04,  1.9620e-04, -4.3386e-04, -2.4531e-03,\n",
      "          8.7821e-04,  2.6805e-03,  2.2786e-03,  2.4526e-03, -3.4327e-04,\n",
      "          4.6185e-04, -4.4231e-04,  2.4494e-03, -1.2904e-03,  3.8308e-04,\n",
      "         -2.4657e-04, -1.3123e-03,  1.7799e-05,  2.6641e-03,  5.2073e-04,\n",
      "          1.1670e-03, -8.1679e-04,  1.1497e-03, -1.5153e-03,  2.0955e-03,\n",
      "         -2.6395e-03, -2.1292e-03, -1.8179e-03,  1.8150e-03,  1.3283e-03,\n",
      "          1.5903e-03,  1.5745e-03,  1.9315e-03, -1.8222e-03,  1.1259e-04,\n",
      "         -2.8296e-04, -5.7316e-04, -1.9386e-03,  6.8561e-04,  1.1507e-03,\n",
      "          2.6021e-03, -1.9429e-03, -9.6961e-04,  2.5654e-03, -1.3693e-03,\n",
      "          1.4003e-03, -1.3685e-03, -2.7465e-03, -2.8373e-03, -1.9280e-03,\n",
      "          2.7926e-03,  4.6174e-04, -2.4763e-03,  2.1184e-03, -2.8265e-03,\n",
      "          2.0998e-03,  1.8003e-03,  2.0006e-03,  2.9734e-04,  1.3133e-03,\n",
      "          1.9460e-03,  8.9787e-04,  1.7178e-03,  1.7930e-03, -2.5729e-03,\n",
      "         -2.8678e-03,  7.1882e-04,  6.2112e-04,  1.5172e-03, -1.1619e-04,\n",
      "         -2.4339e-03, -1.8800e-03,  7.6304e-04,  2.7836e-03,  2.1627e-03,\n",
      "         -1.5058e-03, -2.8395e-03, -1.7967e-03, -1.4769e-03, -2.6288e-03,\n",
      "         -1.1268e-03, -1.9277e-03, -1.5690e-03,  5.7986e-04, -3.2777e-05,\n",
      "         -1.2130e-03,  1.2897e-03,  1.8771e-03,  7.4602e-04, -1.7096e-03,\n",
      "          1.6621e-03,  1.9995e-03, -2.7412e-03, -2.5508e-03, -5.4591e-04,\n",
      "         -1.3999e-03,  1.8513e-03,  2.9377e-03,  1.8018e-03, -6.3333e-04,\n",
      "         -1.0549e-03, -2.3357e-03, -1.8275e-04, -2.4472e-03, -1.1821e-03,\n",
      "          3.9020e-04,  2.7019e-03, -7.8878e-05, -2.0986e-03, -1.3609e-03,\n",
      "         -2.0301e-03, -2.7179e-03, -2.4656e-04, -9.8130e-04,  2.9810e-03,\n",
      "          1.4580e-03,  2.3453e-03, -4.2945e-04,  5.5684e-04, -2.2070e-03,\n",
      "          1.5327e-03, -2.0818e-03,  7.4101e-04, -9.6831e-04, -4.5662e-04,\n",
      "          9.4436e-04, -1.1977e-03,  2.6110e-03,  1.0674e-04,  4.5386e-04,\n",
      "          1.2776e-03,  1.5145e-03, -1.5098e-04,  7.2817e-04, -8.5021e-04],\n",
      "        [ 1.7696e-03,  4.0410e-04,  2.2403e-03,  2.6778e-03,  1.1074e-03,\n",
      "          1.4964e-03, -1.0697e-04,  2.1880e-04,  2.7519e-03, -1.0893e-03,\n",
      "          2.7974e-03,  2.5866e-03, -2.4200e-04,  2.8425e-03,  2.5332e-03,\n",
      "          2.3415e-03,  2.4192e-03,  8.3880e-04,  2.6921e-03, -1.9036e-03,\n",
      "         -7.9658e-04,  1.6491e-03,  2.8127e-03, -6.8776e-04,  2.8367e-03,\n",
      "          1.4248e-03,  8.5993e-05, -2.5407e-03, -2.8165e-03, -2.9578e-04,\n",
      "         -4.2851e-04, -1.4503e-03,  8.9682e-04,  2.5555e-03,  2.3917e-03,\n",
      "          1.7393e-03,  4.5933e-04, -1.3372e-03,  1.5792e-03, -3.7826e-04,\n",
      "          8.8215e-04,  1.7144e-03,  2.4434e-03,  8.0311e-04,  2.1636e-03,\n",
      "          8.2437e-04, -1.4044e-03, -1.2958e-03,  2.8509e-03, -1.2725e-03,\n",
      "         -2.1105e-03,  6.5406e-04,  2.8423e-03, -1.8262e-03,  1.6268e-03,\n",
      "         -2.7902e-03,  5.8833e-04, -1.7650e-03,  3.6120e-04, -1.8257e-03,\n",
      "         -1.8695e-03,  1.6226e-03, -1.0152e-03, -1.0933e-03, -4.3764e-04,\n",
      "          4.3556e-06, -2.3185e-03, -2.5590e-03,  2.8364e-03,  1.8839e-03,\n",
      "         -2.0084e-03, -2.4943e-03,  2.7319e-03,  6.0322e-04, -2.1507e-03,\n",
      "          1.0059e-04, -2.0955e-03, -1.6318e-03, -9.3257e-04, -1.3241e-03,\n",
      "          1.8503e-03,  6.3659e-04,  1.4395e-03,  2.1451e-03,  1.4249e-03,\n",
      "         -4.1372e-04, -8.1875e-04, -9.7366e-04, -1.4037e-03, -2.1054e-03,\n",
      "         -1.3695e-03, -1.0252e-03,  2.2567e-03, -8.6136e-04,  7.7608e-04,\n",
      "          1.9243e-03, -8.0798e-04,  1.2421e-03,  2.9818e-03,  1.3128e-03,\n",
      "          2.6290e-03,  2.5918e-03, -2.4754e-03,  2.9427e-03, -1.6234e-03,\n",
      "         -2.1235e-03, -6.4536e-05,  2.2005e-03,  1.7920e-03,  9.4132e-04,\n",
      "          2.9871e-03,  5.4427e-04, -1.5611e-03,  2.7570e-03,  4.1961e-04,\n",
      "         -1.8046e-04, -1.2921e-03, -2.0604e-03, -1.3476e-03, -1.4999e-03,\n",
      "          2.9327e-03, -2.2021e-03, -2.0248e-03,  1.2215e-03, -2.3251e-03,\n",
      "         -1.6664e-03, -2.7740e-03,  2.6792e-03,  2.1036e-03, -1.4937e-03,\n",
      "          9.4083e-04, -1.4386e-03, -1.4908e-03,  5.3712e-04,  1.7657e-03,\n",
      "         -1.9262e-03,  2.9725e-03,  9.6992e-04,  2.9227e-03,  5.2619e-04,\n",
      "          1.4253e-03, -2.0692e-03,  1.7285e-03, -7.4456e-04,  1.4652e-03,\n",
      "          2.1727e-03,  1.5288e-03,  8.2879e-04, -2.9363e-03, -2.4641e-03],\n",
      "        [ 7.0225e-04, -9.5906e-04,  1.9834e-03, -2.5768e-03, -1.7336e-03,\n",
      "          7.2179e-04,  9.1879e-04, -2.0423e-04, -1.2401e-03, -2.6154e-03,\n",
      "         -2.2021e-03,  7.9007e-04, -2.7112e-03, -2.2982e-04,  1.6240e-03,\n",
      "         -1.9843e-03, -2.5940e-03,  9.2828e-04,  7.9288e-04,  1.1185e-03,\n",
      "          2.7582e-03,  2.3784e-03, -1.0325e-03, -2.2498e-03, -1.4233e-03,\n",
      "          6.6819e-04,  1.8638e-03, -8.3060e-04,  1.8226e-03,  5.2559e-04,\n",
      "         -2.7499e-05,  3.2730e-04, -2.0351e-03,  2.1525e-03,  1.9481e-03,\n",
      "          1.7517e-03, -1.9526e-03,  2.0235e-03, -2.5124e-03,  5.2176e-04,\n",
      "         -2.7440e-03,  1.2426e-03, -1.8790e-03,  1.2681e-04,  7.0647e-05,\n",
      "         -5.9319e-05, -4.8878e-04,  9.3032e-04, -1.1648e-03, -1.9436e-03,\n",
      "          1.5880e-03,  8.8550e-04,  2.1720e-03, -2.9019e-03,  2.3284e-03,\n",
      "          1.1333e-03, -5.6456e-05, -1.5830e-03,  1.5537e-03,  2.2008e-03,\n",
      "          2.2090e-03, -2.5528e-06,  1.3745e-03,  9.8401e-04,  6.9294e-04,\n",
      "          6.2053e-04,  1.4306e-03, -2.6959e-03, -1.9312e-03, -2.3526e-03,\n",
      "         -2.0485e-03,  2.6853e-03,  2.6160e-03, -9.6998e-04, -2.0558e-03,\n",
      "         -2.9693e-03, -1.0563e-03, -1.0810e-03,  8.4147e-04,  1.0904e-03,\n",
      "          2.2807e-03,  1.4837e-03,  2.0448e-03,  1.6295e-03, -2.1082e-03,\n",
      "         -1.5462e-03,  3.7170e-04, -2.6681e-03,  1.3037e-03,  5.7642e-05,\n",
      "         -1.1997e-03,  1.6857e-03, -2.6268e-03, -1.2508e-03, -1.9717e-03,\n",
      "         -1.2956e-03, -2.5695e-03,  4.6111e-04,  2.9954e-03,  2.5419e-03,\n",
      "         -4.9218e-04, -1.7876e-03,  2.0461e-03, -1.4607e-03,  2.6162e-03,\n",
      "          4.4205e-04, -1.4786e-03, -2.3284e-03, -1.0695e-04, -1.7459e-03,\n",
      "          1.1640e-03, -1.5274e-03,  1.8837e-03,  2.5625e-03, -1.5324e-03,\n",
      "         -8.6830e-04,  2.4537e-03,  2.5976e-03,  2.7702e-03, -3.7810e-04,\n",
      "          4.7926e-04, -2.6407e-03,  3.2806e-04,  1.6948e-03, -2.3983e-04,\n",
      "         -6.3841e-04,  1.6455e-03, -2.4524e-03, -2.5935e-04, -1.2073e-03,\n",
      "         -2.1059e-03, -1.0788e-03, -6.8062e-04,  2.2106e-03, -1.5311e-03,\n",
      "          9.1683e-04,  1.0323e-03,  4.8202e-04,  2.4183e-03, -2.7148e-03,\n",
      "          9.1667e-04, -1.6463e-03,  1.5846e-03, -1.1105e-03,  1.0816e-04,\n",
      "         -2.1166e-03,  1.9448e-03,  1.6832e-03,  1.3391e-03,  1.6371e-03],\n",
      "        [ 2.9777e-03,  1.6673e-03, -2.7159e-03,  2.8444e-03,  2.9795e-03,\n",
      "          2.2353e-03, -7.8059e-04,  1.9282e-03, -5.0413e-04, -8.3462e-04,\n",
      "          5.6530e-04, -1.3999e-03,  6.9331e-04, -9.9781e-04,  7.3409e-04,\n",
      "         -5.3579e-04,  1.2795e-03, -1.6623e-04, -2.6921e-03, -1.9972e-03,\n",
      "          1.0986e-03, -2.5741e-03, -2.6631e-03, -2.0177e-03, -4.5485e-04,\n",
      "         -2.7250e-03,  1.7866e-04, -1.8964e-03, -2.5157e-03,  6.0161e-04,\n",
      "         -1.5780e-03,  2.6978e-03,  1.5195e-03,  9.7776e-04, -1.6783e-03,\n",
      "         -2.2401e-03,  2.7982e-03, -2.7066e-03,  1.6085e-04, -1.7263e-04,\n",
      "         -1.1277e-03,  8.1666e-04,  5.2615e-04,  2.4864e-03, -4.5182e-04,\n",
      "         -9.2819e-04,  1.0586e-03, -2.9077e-03, -2.7737e-03,  2.3719e-03,\n",
      "         -8.6004e-04,  1.7299e-03,  2.0316e-03,  1.7754e-03, -5.3557e-05,\n",
      "         -2.9993e-03, -1.0821e-03, -2.3162e-03,  2.3991e-03,  2.5026e-03,\n",
      "         -2.5572e-04,  1.1017e-03,  1.9887e-03, -5.8746e-04,  1.2293e-03,\n",
      "         -2.6955e-03, -8.0850e-05,  8.1563e-04, -1.8856e-03, -2.5654e-03,\n",
      "          1.5300e-03,  1.3444e-03,  1.8642e-03,  2.5489e-03, -2.3427e-03,\n",
      "          1.2127e-03,  1.4833e-03, -2.0484e-03, -4.6620e-04, -1.9748e-03,\n",
      "          2.1179e-04,  2.8501e-03, -2.0235e-03,  6.1039e-04, -1.4506e-03,\n",
      "         -2.0370e-03,  2.4885e-03, -2.3595e-03,  2.6428e-03, -6.9786e-04,\n",
      "         -2.5559e-03, -8.5478e-04, -7.5585e-04,  1.4207e-03, -2.8148e-03,\n",
      "         -2.5600e-03, -6.2796e-04, -2.9714e-03, -1.0967e-03, -2.3299e-05,\n",
      "         -1.7697e-03,  6.7006e-04, -2.4928e-03,  7.9875e-04, -2.2936e-03,\n",
      "          2.4098e-03, -1.2569e-03,  1.1528e-03,  6.6508e-04,  1.5995e-03,\n",
      "          2.4588e-04,  2.6335e-03, -2.2244e-03,  2.8003e-03, -2.2338e-04,\n",
      "         -2.1648e-03,  2.1195e-03, -2.1193e-03, -2.7550e-03,  2.0736e-03,\n",
      "         -2.4561e-03, -1.0823e-03, -2.8796e-04,  1.9782e-03, -4.2107e-04,\n",
      "          1.9303e-03,  2.4631e-03, -1.8889e-03,  1.5048e-03,  1.6886e-03,\n",
      "          2.2749e-03, -4.8818e-04, -5.8305e-04,  2.5849e-03,  2.6939e-03,\n",
      "         -2.4812e-03, -1.2939e-03, -2.3375e-03, -6.6156e-04,  4.2612e-04,\n",
      "         -6.5681e-04,  2.5881e-03, -1.4401e-03,  2.4971e-05, -8.3317e-04,\n",
      "         -1.1694e-03,  2.2708e-03, -4.8583e-04,  8.3089e-04, -1.6915e-03]])), ('head.bias', tensor([-0.0021, -0.0192,  0.0363,  0.0157]))])\n",
      "INFO:rllib.models:Initialized DeepNeuralNetHeadCritic with body : ModuleList(\n",
      "  (0): Linear(in_features=33, out_features=400, bias=True)\n",
      ") and head ModuleList(\n",
      "  (0): Linear(in_features=404, out_features=300, bias=True)\n",
      "  (1): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n",
      "INFO:rllib.models:state_dict= OrderedDict([('body.layers.0.weight', tensor([[-1.0039e-03, -2.7219e-02, -5.8732e-03,  ..., -3.5667e-02,\n",
      "          1.3713e-02,  4.2372e-02],\n",
      "        [ 3.1677e-02,  2.4817e-02, -4.7929e-02,  ...,  4.7579e-02,\n",
      "         -1.8188e-02, -1.3225e-02],\n",
      "        [ 2.7205e-03, -2.6465e-02,  2.5049e-02,  ..., -1.4964e-02,\n",
      "          5.4236e-03,  3.4415e-02],\n",
      "        ...,\n",
      "        [ 1.4893e-02,  4.9692e-02,  4.9638e-02,  ..., -3.5418e-03,\n",
      "         -7.0493e-03, -2.8474e-02],\n",
      "        [ 1.9417e-02,  6.5405e-05, -2.5932e-03,  ..., -4.7790e-02,\n",
      "          3.9044e-02,  3.7796e-03],\n",
      "        [-1.8730e-02, -2.0211e-02, -3.4439e-02,  ..., -2.7822e-02,\n",
      "          1.8316e-03, -4.1569e-02]])), ('body.layers.0.bias', tensor([ 0.1115, -0.0475, -0.0453, -0.0988, -0.0170,  0.1346,  0.1454,  0.1366,\n",
      "         0.0759, -0.0599, -0.0941, -0.0004,  0.0041, -0.1202, -0.0629,  0.0118,\n",
      "         0.1569, -0.0426, -0.0631, -0.0019,  0.0698,  0.0948, -0.0984,  0.0503,\n",
      "        -0.0746,  0.0976, -0.1320,  0.1562, -0.0791,  0.1647, -0.0317, -0.0275,\n",
      "         0.1300,  0.0718,  0.0595,  0.1682, -0.1566, -0.0688,  0.0940, -0.1207,\n",
      "        -0.1634, -0.0954,  0.1609, -0.0713, -0.1259,  0.1569, -0.0619,  0.1065,\n",
      "        -0.0516, -0.0017,  0.0136,  0.0735,  0.1289,  0.1284,  0.1582,  0.0126,\n",
      "        -0.1682, -0.0317,  0.1004,  0.0911,  0.0319, -0.1242, -0.0605,  0.0814,\n",
      "         0.1518, -0.0969, -0.1010,  0.1626, -0.1462,  0.0808,  0.1277,  0.0560,\n",
      "        -0.0170,  0.1510,  0.0934,  0.1542,  0.0601, -0.1703,  0.0645, -0.0937,\n",
      "         0.0062, -0.0835, -0.0940, -0.0426,  0.0216, -0.0367, -0.0926,  0.1071,\n",
      "        -0.1436, -0.1202,  0.0264, -0.0252,  0.1098, -0.1190, -0.1298, -0.1009,\n",
      "         0.1614,  0.1383, -0.0168,  0.0499, -0.1265,  0.1073,  0.1102,  0.0270,\n",
      "        -0.0927,  0.1201, -0.0116,  0.0035,  0.1679,  0.1667, -0.1088, -0.1046,\n",
      "         0.0998, -0.0325,  0.0171,  0.1026,  0.0088,  0.0547,  0.0323,  0.0411,\n",
      "        -0.0324, -0.1186, -0.1283,  0.0850, -0.0057, -0.0719,  0.0835, -0.1325,\n",
      "        -0.0260,  0.1703, -0.0660, -0.1526,  0.0579,  0.1232, -0.0521, -0.0423,\n",
      "        -0.1363, -0.0116,  0.0257,  0.1102,  0.0366,  0.0276, -0.0858,  0.0899,\n",
      "        -0.1518, -0.0920,  0.0939, -0.0367, -0.0617,  0.0028, -0.1451,  0.0705,\n",
      "         0.0723, -0.0841, -0.0860,  0.0754, -0.0204,  0.1315, -0.0390,  0.0258,\n",
      "        -0.0191,  0.0657, -0.1674,  0.1706, -0.1422, -0.0830,  0.0068, -0.1535,\n",
      "        -0.1438, -0.1642,  0.1518, -0.1187,  0.1379,  0.0902, -0.0276, -0.0340,\n",
      "        -0.0890,  0.0211,  0.0345,  0.1273, -0.1002, -0.0276, -0.1567,  0.0159,\n",
      "        -0.0123, -0.1362, -0.0277, -0.1638, -0.0260,  0.0859,  0.0963, -0.1428,\n",
      "        -0.0480,  0.0335,  0.1013,  0.1634, -0.1130,  0.0935, -0.1733,  0.0139,\n",
      "         0.0976, -0.0237,  0.1460, -0.0157, -0.0951,  0.1553,  0.0225,  0.1504,\n",
      "         0.0118, -0.1448,  0.0990, -0.1046,  0.0621, -0.1553, -0.1046,  0.0867,\n",
      "        -0.0597, -0.1706,  0.0114,  0.1263,  0.1332, -0.0081, -0.0495,  0.0891,\n",
      "         0.1310, -0.0557, -0.0196, -0.0267,  0.0249,  0.0243, -0.1599, -0.1637,\n",
      "        -0.1195, -0.0086, -0.0181, -0.0271,  0.1390,  0.1537, -0.1527, -0.0592,\n",
      "        -0.0400, -0.1192, -0.1481,  0.1596, -0.1028,  0.0529,  0.1395,  0.1254,\n",
      "         0.0722,  0.0700, -0.0084,  0.1656, -0.1536,  0.0589, -0.1111, -0.1080,\n",
      "         0.0347,  0.1586,  0.1344,  0.0043,  0.0167, -0.1146,  0.0227, -0.0061,\n",
      "        -0.1409,  0.1246, -0.0151,  0.0851,  0.0139,  0.0691,  0.1208,  0.1273,\n",
      "         0.0694,  0.1036, -0.0226, -0.0362,  0.1679, -0.0577,  0.0952,  0.0716,\n",
      "        -0.0835,  0.0217,  0.1179, -0.1383,  0.1672,  0.0961,  0.0228,  0.1199,\n",
      "         0.1350, -0.0790,  0.0975,  0.1313,  0.0206,  0.0295, -0.0558, -0.1489,\n",
      "        -0.0350, -0.0872,  0.0667, -0.0627,  0.1630,  0.0008,  0.1296, -0.0936,\n",
      "        -0.1563,  0.0892,  0.0581, -0.0044, -0.0655, -0.0123, -0.0895,  0.1720,\n",
      "         0.0254, -0.1530, -0.1539,  0.0255, -0.1374, -0.0932,  0.1320, -0.0627,\n",
      "        -0.0547,  0.1521, -0.0800, -0.0515, -0.0341, -0.1722, -0.0485,  0.0603,\n",
      "         0.0898,  0.1279, -0.1590,  0.1424,  0.1149, -0.0640, -0.0574, -0.1151,\n",
      "        -0.1738,  0.0735,  0.0794,  0.0754, -0.0604,  0.1540, -0.0668, -0.1053,\n",
      "         0.1351,  0.0592,  0.0034,  0.0702, -0.1303, -0.1610, -0.0034,  0.1242,\n",
      "         0.0571,  0.0793,  0.0412,  0.0868,  0.0522,  0.0672, -0.0867,  0.1456,\n",
      "         0.1356, -0.1358, -0.0336, -0.0552, -0.0046,  0.0198,  0.0149,  0.0892,\n",
      "        -0.0477, -0.0353,  0.0413,  0.1105,  0.1051, -0.1015, -0.1472,  0.1567,\n",
      "        -0.0116, -0.1177, -0.0884,  0.1583, -0.0139,  0.1540,  0.0217, -0.1364,\n",
      "        -0.0344, -0.1436,  0.0788, -0.1570, -0.0780,  0.1340,  0.1612,  0.0063,\n",
      "         0.0303, -0.1567,  0.0101,  0.0339, -0.0365, -0.0195, -0.1346, -0.1292])), ('layers.0.weight', tensor([[ 0.0407, -0.0032,  0.0504,  ...,  0.0386, -0.0090, -0.0058],\n",
      "        [ 0.0476, -0.0555,  0.0092,  ...,  0.0136, -0.0142,  0.0229],\n",
      "        [ 0.0511, -0.0288,  0.0399,  ..., -0.0185,  0.0575,  0.0123],\n",
      "        ...,\n",
      "        [ 0.0036, -0.0474, -0.0509,  ..., -0.0061,  0.0501,  0.0351],\n",
      "        [ 0.0250, -0.0200,  0.0559,  ..., -0.0337, -0.0088,  0.0447],\n",
      "        [ 0.0420, -0.0218, -0.0367,  ..., -0.0245,  0.0182,  0.0280]])), ('layers.0.bias', tensor([ 0.0235, -0.0315,  0.0219, -0.0231,  0.0173,  0.0180, -0.0328, -0.0009,\n",
      "        -0.0363, -0.0281, -0.0401, -0.0100, -0.0219, -0.0362,  0.0266, -0.0280,\n",
      "        -0.0288,  0.0406,  0.0349,  0.0256, -0.0484,  0.0247, -0.0407,  0.0121,\n",
      "         0.0373,  0.0455, -0.0231,  0.0202, -0.0190, -0.0337,  0.0261, -0.0369,\n",
      "         0.0411,  0.0144, -0.0099,  0.0438, -0.0290, -0.0179,  0.0221, -0.0240,\n",
      "         0.0202,  0.0065, -0.0012,  0.0189, -0.0255, -0.0347,  0.0267, -0.0372,\n",
      "        -0.0285, -0.0399, -0.0447,  0.0450,  0.0308, -0.0411, -0.0142,  0.0477,\n",
      "        -0.0169,  0.0405,  0.0467,  0.0246, -0.0482,  0.0139,  0.0105,  0.0153,\n",
      "         0.0008, -0.0160, -0.0192,  0.0305, -0.0087, -0.0226,  0.0357, -0.0222,\n",
      "         0.0369, -0.0147, -0.0340,  0.0377, -0.0483,  0.0231, -0.0460,  0.0035,\n",
      "         0.0477, -0.0303,  0.0050, -0.0065, -0.0024,  0.0451, -0.0151,  0.0347,\n",
      "         0.0354, -0.0424,  0.0132, -0.0380, -0.0014, -0.0234,  0.0423, -0.0124,\n",
      "         0.0097,  0.0429, -0.0311, -0.0307,  0.0476, -0.0048,  0.0036,  0.0349,\n",
      "        -0.0228,  0.0448,  0.0207, -0.0411,  0.0378, -0.0238, -0.0316, -0.0450,\n",
      "        -0.0038, -0.0210, -0.0353, -0.0347, -0.0032,  0.0332, -0.0409,  0.0135,\n",
      "        -0.0004,  0.0185, -0.0421, -0.0143, -0.0161,  0.0490,  0.0152, -0.0289,\n",
      "         0.0019, -0.0354,  0.0148,  0.0480,  0.0239, -0.0352, -0.0244, -0.0443,\n",
      "        -0.0156,  0.0222, -0.0293,  0.0384,  0.0487, -0.0010,  0.0311,  0.0111,\n",
      "        -0.0317, -0.0448, -0.0141, -0.0417,  0.0306, -0.0082,  0.0213, -0.0028,\n",
      "        -0.0144, -0.0062, -0.0323,  0.0315,  0.0258,  0.0314,  0.0296, -0.0458,\n",
      "         0.0176,  0.0134, -0.0469, -0.0013, -0.0372,  0.0120, -0.0058, -0.0414,\n",
      "         0.0448,  0.0451, -0.0485,  0.0333,  0.0399,  0.0225,  0.0133, -0.0161,\n",
      "         0.0370, -0.0028,  0.0062, -0.0199, -0.0257, -0.0427,  0.0366, -0.0068,\n",
      "         0.0175,  0.0323,  0.0183,  0.0060, -0.0355, -0.0242,  0.0078, -0.0092,\n",
      "        -0.0139, -0.0186, -0.0223, -0.0297,  0.0226, -0.0267,  0.0419,  0.0136,\n",
      "         0.0002,  0.0058, -0.0107, -0.0423, -0.0212,  0.0044, -0.0350,  0.0140,\n",
      "        -0.0137, -0.0212,  0.0443,  0.0389, -0.0462, -0.0303,  0.0031,  0.0047,\n",
      "         0.0394, -0.0390,  0.0060, -0.0406, -0.0273, -0.0209,  0.0352,  0.0019,\n",
      "        -0.0117,  0.0019,  0.0357,  0.0070,  0.0144, -0.0486, -0.0321,  0.0454,\n",
      "         0.0170,  0.0452,  0.0407, -0.0360, -0.0358, -0.0221, -0.0163,  0.0233,\n",
      "        -0.0461, -0.0373,  0.0390, -0.0292, -0.0390, -0.0220,  0.0260, -0.0052,\n",
      "         0.0259,  0.0127,  0.0426,  0.0149,  0.0141,  0.0058,  0.0275, -0.0298,\n",
      "        -0.0111,  0.0236,  0.0077, -0.0079,  0.0468, -0.0202, -0.0230, -0.0391,\n",
      "        -0.0420, -0.0403,  0.0157, -0.0009, -0.0198,  0.0186, -0.0125, -0.0007,\n",
      "        -0.0191, -0.0034, -0.0211,  0.0297,  0.0295,  0.0084, -0.0029,  0.0098,\n",
      "         0.0109,  0.0431, -0.0398, -0.0151, -0.0111,  0.0436,  0.0299,  0.0212,\n",
      "        -0.0448, -0.0248,  0.0216,  0.0279, -0.0036,  0.0053, -0.0085, -0.0147,\n",
      "        -0.0170, -0.0195, -0.0231, -0.0263])), ('layers.1.weight', tensor([[-2.0933e-03, -5.1861e-04,  2.4117e-03,  2.0135e-03,  6.2088e-04,\n",
      "         -1.6003e-03,  5.0686e-04, -1.4520e-03, -2.9161e-03, -8.6263e-04,\n",
      "         -5.0023e-04,  2.1358e-03,  4.9605e-04, -1.4883e-03, -1.3740e-03,\n",
      "          2.7427e-03,  1.0385e-03, -1.7977e-03,  6.7696e-04,  2.9149e-03,\n",
      "          2.1031e-03, -2.5760e-03,  2.0780e-03,  3.1518e-04,  1.8208e-03,\n",
      "         -2.4925e-03,  2.3129e-03,  1.1396e-03, -2.7093e-03,  1.0462e-03,\n",
      "         -2.6693e-03,  8.5851e-04, -7.8827e-04,  9.3523e-04, -2.2808e-03,\n",
      "         -2.6408e-03,  1.0244e-03, -1.9708e-04, -2.8662e-03,  1.8142e-03,\n",
      "         -2.7692e-03,  2.0047e-03, -2.4691e-03,  2.1075e-03, -2.7183e-03,\n",
      "          2.9220e-03,  2.1894e-04, -2.3825e-03,  1.5924e-03, -2.2496e-03,\n",
      "         -1.0703e-03,  1.9907e-03,  2.1727e-03, -2.6967e-03,  2.4454e-03,\n",
      "          8.7768e-04, -1.1161e-03,  2.8511e-03,  8.3367e-04, -7.0662e-04,\n",
      "          1.7985e-03,  2.3185e-03,  1.3914e-04, -1.8921e-03, -2.8828e-03,\n",
      "         -2.8962e-04,  2.2757e-03,  1.9919e-03, -9.1495e-04,  2.0883e-03,\n",
      "         -2.9547e-03,  2.2702e-03,  9.0584e-04, -2.8640e-03,  2.6480e-03,\n",
      "         -2.4890e-03,  7.6168e-04,  2.7735e-03, -1.9365e-03, -2.9762e-03,\n",
      "          1.5266e-03,  2.6220e-03,  2.4529e-04,  1.9581e-03,  1.4202e-03,\n",
      "          2.2103e-03,  1.0204e-03, -9.7102e-04, -5.9639e-04,  1.1855e-04,\n",
      "          1.0989e-03, -3.3099e-04,  1.2286e-03,  1.0424e-03,  2.7454e-03,\n",
      "          2.3589e-03,  2.7177e-03,  9.0152e-04, -4.8545e-04, -5.4822e-04,\n",
      "          5.4612e-04, -1.3501e-03, -1.9982e-03, -2.1575e-03, -1.2879e-03,\n",
      "         -1.4524e-03, -1.0432e-04,  1.9297e-03,  5.9031e-04,  1.7523e-03,\n",
      "         -2.9028e-03, -2.6887e-04, -8.8821e-04, -2.8627e-03, -5.6093e-04,\n",
      "          3.5406e-04, -2.5945e-03, -1.0979e-03, -5.1927e-04, -1.7887e-03,\n",
      "         -1.1966e-03, -7.1329e-04,  2.4149e-03,  1.0392e-04, -2.6389e-03,\n",
      "         -1.3440e-03,  2.7890e-03, -2.5555e-03,  1.9179e-03, -1.0876e-03,\n",
      "         -2.2671e-03,  9.9971e-04, -6.2316e-04, -1.5387e-03, -9.4261e-04,\n",
      "          3.7359e-04,  6.6345e-04, -2.4537e-03,  1.2115e-03,  1.3773e-03,\n",
      "          1.3066e-03,  1.2675e-03, -1.3312e-03,  7.6229e-04,  8.7785e-04,\n",
      "         -4.4607e-04, -1.8359e-03,  1.6815e-03,  9.9908e-04, -9.3115e-04,\n",
      "          1.9054e-03, -2.9389e-03, -1.2960e-03,  9.8059e-04,  1.8757e-03,\n",
      "          3.5217e-04,  4.5006e-04,  2.2917e-03, -5.4974e-04,  1.0704e-03,\n",
      "         -2.7346e-03,  1.2651e-03,  1.7834e-03,  1.3937e-04,  2.9393e-03,\n",
      "         -7.0544e-04,  4.0978e-04, -2.2974e-03, -2.6255e-03,  6.1268e-05,\n",
      "         -2.9437e-03,  1.4635e-03,  2.3021e-03, -9.0050e-04, -1.2525e-03,\n",
      "         -9.8360e-04, -2.7732e-03,  8.7632e-04, -1.3053e-03, -2.3826e-03,\n",
      "         -1.5816e-04,  1.5922e-03,  2.5703e-03, -1.4508e-03,  4.8487e-04,\n",
      "          8.7097e-04,  1.2982e-03,  1.1951e-03, -1.1833e-03,  2.3502e-03,\n",
      "          1.2690e-03,  5.7600e-05,  2.9491e-03,  2.9535e-03, -1.6949e-03,\n",
      "          6.0880e-04,  3.0557e-04, -1.8423e-03,  2.3512e-03,  2.2436e-03,\n",
      "         -2.0768e-03,  1.7713e-03,  2.7385e-03, -1.8421e-04,  2.9204e-03,\n",
      "          2.0564e-04,  1.7986e-03, -5.0048e-04,  2.2841e-03,  2.4066e-03,\n",
      "          7.7915e-04, -7.9767e-04,  1.1164e-03,  6.6927e-04,  2.1637e-04,\n",
      "          1.3847e-03, -4.8828e-04, -1.7735e-03, -2.0506e-03, -2.3088e-03,\n",
      "          2.1060e-03, -1.2054e-04,  4.6713e-06, -3.9963e-04, -1.9434e-03,\n",
      "          1.6646e-03, -2.5735e-03,  1.0444e-03, -2.5556e-03,  6.2848e-04,\n",
      "          5.8016e-04,  9.6299e-04,  1.2918e-03,  2.2790e-03, -1.3217e-03,\n",
      "          1.2995e-05,  9.8875e-04,  2.3300e-03, -2.8800e-03,  1.4951e-03,\n",
      "         -1.1904e-03, -2.1499e-03,  2.9459e-04,  2.8355e-03,  2.1151e-03,\n",
      "         -2.0851e-03,  6.1964e-04, -2.5054e-03,  2.4196e-03,  2.5493e-03,\n",
      "         -2.7839e-03, -2.2396e-03, -3.1250e-04, -1.0616e-03,  2.3677e-03,\n",
      "          1.5108e-03,  2.1770e-03, -2.0818e-03,  1.5383e-03,  1.5336e-03,\n",
      "         -2.9193e-03,  5.1018e-04,  1.1577e-03,  5.6829e-04, -2.7325e-03,\n",
      "         -2.2370e-03,  1.6988e-03, -1.5250e-03, -8.2059e-04, -1.0590e-03,\n",
      "         -2.7713e-03,  2.4082e-03, -1.4553e-03, -1.0226e-03, -2.0679e-03,\n",
      "         -2.8227e-03,  8.0602e-04, -7.2216e-05, -6.1928e-04, -1.6419e-03,\n",
      "          2.4400e-03, -1.0497e-03, -5.7043e-04,  4.8348e-05,  4.1770e-04,\n",
      "          1.8755e-03,  2.3050e-03, -6.3875e-04,  1.3045e-03,  1.6472e-03,\n",
      "         -5.4540e-04,  2.3134e-03,  2.5736e-03,  2.9489e-04, -2.5567e-03,\n",
      "         -2.5052e-04,  2.0309e-03, -1.9803e-03,  1.3829e-03, -2.8700e-03]])), ('layers.1.bias', tensor([0.0434]))])\n",
      "INFO:rllib.models:Initialized DeepNeuralNetHeadCritic with body : ModuleList(\n",
      "  (0): Linear(in_features=33, out_features=400, bias=True)\n",
      ") and head ModuleList(\n",
      "  (0): Linear(in_features=404, out_features=300, bias=True)\n",
      "  (1): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n",
      "INFO:rllib.models:state_dict= OrderedDict([('body.layers.0.weight', tensor([[-0.0415,  0.0021, -0.0361,  ...,  0.0424, -0.0358, -0.0475],\n",
      "        [ 0.0418,  0.0027,  0.0028,  ..., -0.0166,  0.0357,  0.0261],\n",
      "        [-0.0232, -0.0133, -0.0087,  ...,  0.0396,  0.0155,  0.0406],\n",
      "        ...,\n",
      "        [-0.0305, -0.0472, -0.0194,  ..., -0.0244,  0.0007, -0.0407],\n",
      "        [ 0.0030, -0.0292,  0.0170,  ...,  0.0320, -0.0019,  0.0346],\n",
      "        [ 0.0211, -0.0077, -0.0079,  ...,  0.0385, -0.0280, -0.0004]])), ('body.layers.0.bias', tensor([-0.1432,  0.1058,  0.1576, -0.1404,  0.0560, -0.1501, -0.0688,  0.1134,\n",
      "        -0.0649,  0.0991, -0.0447,  0.1599,  0.0862,  0.0472,  0.1621,  0.1170,\n",
      "         0.0798,  0.0187,  0.0888, -0.0655, -0.1271, -0.0707, -0.0765, -0.1487,\n",
      "        -0.0553, -0.1611, -0.1213, -0.0487,  0.0864,  0.0783, -0.1375, -0.0526,\n",
      "         0.0728,  0.0474, -0.0518,  0.1089, -0.0182,  0.0130,  0.0196, -0.0534,\n",
      "        -0.0037, -0.0382, -0.1419,  0.0899,  0.0723, -0.0410,  0.0185,  0.0239,\n",
      "        -0.1473,  0.0137,  0.0937,  0.1428, -0.1199,  0.1190, -0.0476,  0.0228,\n",
      "        -0.1169, -0.0988, -0.1025,  0.1035,  0.1005,  0.0306, -0.0639,  0.0012,\n",
      "        -0.1347,  0.1611,  0.1711, -0.0801, -0.1404,  0.0552, -0.1112,  0.0918,\n",
      "        -0.1687,  0.1022,  0.1024, -0.1483, -0.0444, -0.0361, -0.0740,  0.0245,\n",
      "        -0.0403, -0.0917,  0.0786, -0.0778,  0.0354, -0.0398,  0.0638,  0.1532,\n",
      "         0.1296, -0.1258,  0.1143,  0.1668,  0.1671,  0.1614, -0.1222,  0.1210,\n",
      "         0.1484, -0.1269, -0.0556,  0.0124, -0.1095, -0.0505,  0.0118, -0.0349,\n",
      "         0.1548, -0.1485, -0.1146, -0.1210, -0.1349,  0.1443, -0.1497,  0.0601,\n",
      "         0.1440, -0.0574,  0.1086, -0.0399, -0.1718,  0.0674, -0.0606,  0.0399,\n",
      "        -0.1039,  0.0613,  0.0868,  0.1594,  0.1620, -0.0334, -0.0932,  0.1656,\n",
      "         0.1129, -0.0672,  0.0022,  0.1375,  0.0149,  0.1713, -0.0649, -0.1260,\n",
      "         0.0654,  0.1056, -0.1739,  0.0897, -0.0701,  0.1650, -0.0457,  0.1103,\n",
      "         0.1356, -0.0319,  0.1602, -0.1438,  0.0776, -0.0161, -0.1511, -0.0619,\n",
      "        -0.1272,  0.0152, -0.1511,  0.1682,  0.0644, -0.1084, -0.0677,  0.0706,\n",
      "         0.0205, -0.0707, -0.1426, -0.1552,  0.0724,  0.0319,  0.1560, -0.0509,\n",
      "        -0.0779, -0.1504, -0.0121, -0.0317,  0.1071, -0.1600, -0.1228,  0.1343,\n",
      "        -0.1314,  0.0144, -0.1291,  0.1007,  0.0929, -0.1653,  0.0974,  0.0387,\n",
      "        -0.0941,  0.1251,  0.0626,  0.1490, -0.1173,  0.0302, -0.1251, -0.1280,\n",
      "         0.1005, -0.1585, -0.0033,  0.0454,  0.0147,  0.0192,  0.0005,  0.1181,\n",
      "         0.0178, -0.0062, -0.0470,  0.0709, -0.1009, -0.0051,  0.1605,  0.0363,\n",
      "         0.1192, -0.0328, -0.0722,  0.0923, -0.1016, -0.0249, -0.1061, -0.1123,\n",
      "         0.1002, -0.0605,  0.1489, -0.1556,  0.0171, -0.1266,  0.1574, -0.1043,\n",
      "         0.0608,  0.1257, -0.1539, -0.0464, -0.0345,  0.0678, -0.0056,  0.1553,\n",
      "        -0.0403, -0.0215,  0.1055, -0.1547, -0.0941,  0.1618, -0.1014,  0.0729,\n",
      "        -0.1023, -0.1157,  0.1583, -0.0112,  0.0374,  0.1404,  0.0905, -0.1305,\n",
      "        -0.0774, -0.1440,  0.0805, -0.0737, -0.1091,  0.0945,  0.0035, -0.1014,\n",
      "        -0.0602,  0.0939, -0.1009, -0.0450, -0.1475,  0.0546, -0.0674,  0.0910,\n",
      "         0.1186, -0.0521,  0.0224, -0.1178,  0.0405, -0.1632,  0.0319,  0.0527,\n",
      "         0.0915, -0.0320,  0.0480, -0.0014, -0.0374, -0.1697,  0.0826,  0.0882,\n",
      "         0.1101, -0.1033,  0.0813,  0.0801,  0.0550,  0.0429, -0.1585, -0.1113,\n",
      "         0.1105,  0.0566, -0.0728, -0.0329, -0.0940, -0.0392, -0.0722,  0.0102,\n",
      "        -0.1581, -0.1576, -0.1033, -0.1020, -0.1637,  0.0718, -0.0911,  0.0864,\n",
      "         0.1651, -0.0286, -0.1687, -0.1504, -0.0518, -0.0498,  0.1161, -0.1066,\n",
      "        -0.1588,  0.1205,  0.0659, -0.0009,  0.1480,  0.0474,  0.0887,  0.0698,\n",
      "         0.1717, -0.0679, -0.1010,  0.0427, -0.0627,  0.0185, -0.0075, -0.0383,\n",
      "         0.1668,  0.0276,  0.0021,  0.0254,  0.1232,  0.0028,  0.0991,  0.0016,\n",
      "         0.1088, -0.0543, -0.1540,  0.0839,  0.0259,  0.0318,  0.0061,  0.0560,\n",
      "        -0.0841, -0.1279,  0.0689, -0.1569, -0.1059,  0.0424,  0.0321,  0.0274,\n",
      "         0.1109,  0.0303,  0.1626,  0.0437, -0.1239,  0.1462,  0.1133, -0.0704,\n",
      "        -0.0631, -0.0231,  0.0532,  0.0218, -0.1505,  0.0023, -0.0833, -0.1719,\n",
      "         0.1118, -0.1000, -0.0103, -0.1074,  0.1550, -0.1674, -0.1089, -0.0329,\n",
      "         0.1300,  0.0353,  0.0815, -0.0762, -0.1536, -0.1290,  0.1261, -0.0606,\n",
      "         0.1112, -0.0149,  0.0754,  0.0454, -0.1629, -0.0876,  0.0413,  0.1168,\n",
      "        -0.0606, -0.0873, -0.0960,  0.1136, -0.0838,  0.0539, -0.1300, -0.0208])), ('layers.0.weight', tensor([[-0.0125,  0.0036,  0.0183,  ..., -0.0395,  0.0460, -0.0527],\n",
      "        [ 0.0242, -0.0259, -0.0533,  ..., -0.0370,  0.0089, -0.0466],\n",
      "        [-0.0494, -0.0233,  0.0372,  ..., -0.0568,  0.0168, -0.0147],\n",
      "        ...,\n",
      "        [-0.0117, -0.0085,  0.0299,  ...,  0.0355,  0.0004,  0.0071],\n",
      "        [-0.0492,  0.0425,  0.0057,  ...,  0.0500,  0.0242,  0.0059],\n",
      "        [ 0.0263,  0.0384,  0.0567,  ...,  0.0295,  0.0083,  0.0001]])), ('layers.0.bias', tensor([ 0.0036,  0.0089,  0.0233,  0.0099, -0.0327, -0.0207, -0.0332, -0.0134,\n",
      "         0.0443, -0.0442, -0.0253, -0.0394,  0.0109,  0.0229, -0.0306, -0.0144,\n",
      "        -0.0162,  0.0124, -0.0017,  0.0345, -0.0329,  0.0049, -0.0061,  0.0076,\n",
      "         0.0020, -0.0023, -0.0424, -0.0192,  0.0283, -0.0281,  0.0007,  0.0015,\n",
      "         0.0038,  0.0008, -0.0099,  0.0490,  0.0369, -0.0410, -0.0044, -0.0024,\n",
      "         0.0039,  0.0305,  0.0429,  0.0212,  0.0168, -0.0162, -0.0296, -0.0188,\n",
      "         0.0331, -0.0045, -0.0298, -0.0035,  0.0088,  0.0377, -0.0173, -0.0037,\n",
      "        -0.0036,  0.0324, -0.0285,  0.0291, -0.0403,  0.0079,  0.0377, -0.0176,\n",
      "         0.0436, -0.0279,  0.0292,  0.0232, -0.0481, -0.0451,  0.0045, -0.0080,\n",
      "         0.0281, -0.0189,  0.0426, -0.0112, -0.0015,  0.0151, -0.0375, -0.0221,\n",
      "         0.0431, -0.0096, -0.0388, -0.0378, -0.0096, -0.0291, -0.0381,  0.0418,\n",
      "         0.0316, -0.0284, -0.0135,  0.0013, -0.0194, -0.0007,  0.0208,  0.0163,\n",
      "         0.0256, -0.0319,  0.0351,  0.0211,  0.0286,  0.0425,  0.0291, -0.0255,\n",
      "         0.0108,  0.0316,  0.0408,  0.0030,  0.0258,  0.0291, -0.0450,  0.0190,\n",
      "         0.0445,  0.0198, -0.0217,  0.0341,  0.0326,  0.0084,  0.0071, -0.0013,\n",
      "        -0.0274, -0.0122,  0.0080, -0.0084, -0.0042, -0.0410,  0.0478, -0.0307,\n",
      "         0.0322,  0.0310,  0.0055,  0.0217,  0.0037,  0.0298,  0.0304, -0.0141,\n",
      "         0.0065, -0.0190,  0.0344, -0.0482, -0.0179,  0.0269, -0.0118, -0.0049,\n",
      "         0.0321, -0.0323, -0.0473, -0.0057,  0.0384, -0.0020, -0.0006,  0.0372,\n",
      "        -0.0337, -0.0348, -0.0201, -0.0113,  0.0256,  0.0385,  0.0427, -0.0373,\n",
      "         0.0026, -0.0253, -0.0425, -0.0225, -0.0162, -0.0497, -0.0108,  0.0065,\n",
      "        -0.0419,  0.0326, -0.0137,  0.0339,  0.0386, -0.0017,  0.0051,  0.0174,\n",
      "        -0.0309, -0.0397,  0.0322, -0.0076,  0.0481, -0.0190, -0.0051,  0.0169,\n",
      "        -0.0372, -0.0177,  0.0236, -0.0352,  0.0477, -0.0200,  0.0260, -0.0138,\n",
      "         0.0421, -0.0144,  0.0472,  0.0410, -0.0296, -0.0089,  0.0106, -0.0243,\n",
      "         0.0382,  0.0176, -0.0345,  0.0251, -0.0303,  0.0220,  0.0240,  0.0191,\n",
      "         0.0333, -0.0040, -0.0118,  0.0271,  0.0209,  0.0320,  0.0063,  0.0126,\n",
      "         0.0020, -0.0372,  0.0310,  0.0107, -0.0017, -0.0120,  0.0485,  0.0229,\n",
      "        -0.0118, -0.0241, -0.0418,  0.0441, -0.0416, -0.0454, -0.0474, -0.0448,\n",
      "         0.0353, -0.0251, -0.0175, -0.0491, -0.0236, -0.0335, -0.0085, -0.0135,\n",
      "        -0.0414, -0.0333, -0.0457, -0.0021,  0.0025, -0.0298,  0.0170, -0.0421,\n",
      "         0.0422,  0.0324, -0.0015,  0.0069,  0.0149,  0.0437,  0.0210, -0.0010,\n",
      "         0.0089, -0.0266, -0.0085,  0.0484,  0.0208,  0.0193,  0.0182,  0.0127,\n",
      "         0.0375, -0.0389,  0.0313,  0.0489, -0.0104,  0.0006,  0.0238, -0.0200,\n",
      "        -0.0485, -0.0052, -0.0301, -0.0363,  0.0026,  0.0003, -0.0425,  0.0214,\n",
      "         0.0057, -0.0398, -0.0413,  0.0410,  0.0307, -0.0060,  0.0190,  0.0030,\n",
      "        -0.0465, -0.0486, -0.0122,  0.0137, -0.0423,  0.0169, -0.0372, -0.0100,\n",
      "        -0.0317,  0.0187,  0.0135,  0.0179])), ('layers.1.weight', tensor([[-2.7986e-03,  9.0515e-04, -1.7825e-03, -8.0213e-04, -2.1850e-03,\n",
      "         -2.9590e-03, -1.8857e-03,  2.6793e-03,  1.0309e-05, -7.2870e-04,\n",
      "          1.7668e-03, -1.3198e-03,  1.2442e-03,  2.4469e-03, -6.5528e-04,\n",
      "          5.6901e-04,  1.3810e-03, -9.2567e-04,  2.5057e-03,  5.6610e-04,\n",
      "          5.3885e-04, -1.7067e-03,  5.0892e-04, -1.5663e-03,  1.1431e-03,\n",
      "         -1.6504e-04,  2.9790e-04,  2.9930e-04,  1.4429e-03, -4.0352e-04,\n",
      "         -1.0333e-03,  1.7320e-03, -2.1775e-03, -1.5286e-03, -1.0976e-04,\n",
      "          5.3443e-04,  1.4643e-03,  8.1035e-04, -2.7280e-03,  2.2669e-03,\n",
      "         -2.9366e-03, -8.6458e-04, -2.7813e-03, -1.3645e-03, -1.5268e-03,\n",
      "          2.3597e-03, -2.3731e-03, -1.7387e-03,  2.2535e-03, -1.6859e-03,\n",
      "          4.5688e-04, -1.3051e-03, -2.3154e-03, -1.2836e-04, -2.5023e-03,\n",
      "          7.3772e-04, -4.4059e-04, -1.6253e-03,  4.5510e-05,  2.3948e-03,\n",
      "         -7.2889e-04,  1.8781e-04,  1.8385e-03, -3.3868e-04,  1.5440e-03,\n",
      "         -1.2795e-03, -1.0937e-03,  2.9129e-03,  8.1257e-05,  1.7789e-05,\n",
      "         -3.4011e-05,  5.5712e-04,  2.7896e-03, -3.7560e-04,  1.0285e-03,\n",
      "          1.5210e-03, -5.9163e-04, -1.7512e-03,  2.4921e-04,  2.6900e-03,\n",
      "          2.0565e-03,  6.2182e-04, -8.3240e-04, -1.9720e-03, -2.3706e-03,\n",
      "         -1.7797e-03,  5.0156e-04, -2.0179e-03, -1.7712e-03, -2.3313e-03,\n",
      "         -2.2065e-03, -2.9708e-03,  2.7101e-03,  2.2895e-03, -1.0080e-03,\n",
      "         -1.5686e-03, -1.1313e-03,  5.0053e-04,  2.1642e-03,  6.5445e-04,\n",
      "         -1.1648e-03,  2.9630e-03, -1.4235e-03,  1.5146e-03, -1.6325e-03,\n",
      "         -2.9123e-03,  2.2226e-03, -1.1815e-04,  2.5419e-03, -2.5640e-03,\n",
      "         -1.0154e-03, -3.8156e-04,  2.5254e-03,  2.0617e-03, -1.3884e-03,\n",
      "          3.8127e-04, -2.4983e-03, -2.0819e-03,  1.3485e-03, -1.6072e-03,\n",
      "          1.5902e-04, -6.9426e-04, -4.8574e-04, -7.7949e-04,  1.6517e-03,\n",
      "         -2.9588e-03,  4.2199e-04,  2.8231e-03, -1.9722e-03,  2.4686e-03,\n",
      "          2.6813e-03, -1.0656e-04,  1.6897e-03,  1.5233e-03, -8.9365e-04,\n",
      "         -3.1873e-05,  1.8143e-03,  2.3675e-03,  1.7302e-03, -1.6945e-03,\n",
      "          1.2680e-03, -8.0656e-04,  9.6024e-04,  2.3567e-03,  2.7901e-03,\n",
      "          2.2849e-03, -2.4658e-04,  2.0013e-03,  2.2050e-04, -1.1113e-04,\n",
      "         -1.5167e-03, -1.5308e-03,  1.6548e-03,  3.8383e-04,  1.5090e-03,\n",
      "          2.1343e-03, -1.5745e-04, -1.7323e-03, -2.2246e-03, -8.0512e-04,\n",
      "          5.2269e-04,  5.2930e-04, -1.3633e-03,  2.9500e-03, -2.9368e-03,\n",
      "          1.5202e-03, -1.0609e-04, -2.6836e-03, -2.1457e-03, -6.5867e-04,\n",
      "         -6.1459e-04, -2.5250e-03,  7.7401e-04, -2.2273e-03, -2.9833e-03,\n",
      "         -7.6814e-05, -4.1857e-04, -2.4613e-03,  1.0389e-03, -2.1675e-03,\n",
      "          2.7051e-03,  2.6317e-03,  1.3301e-03, -7.7259e-04,  1.1977e-03,\n",
      "          2.2893e-03,  1.1003e-03,  1.6642e-03, -1.3981e-03,  2.6777e-03,\n",
      "          6.7991e-05,  1.9564e-03,  1.2213e-03,  2.2560e-03, -5.2664e-04,\n",
      "          6.2162e-04,  9.2679e-04, -2.5915e-03,  2.9148e-04, -2.1304e-03,\n",
      "          1.8659e-03,  2.1511e-03, -2.3669e-04, -2.0168e-03,  1.8397e-03,\n",
      "          2.7308e-03,  8.8321e-04,  1.6603e-03,  1.0552e-03,  5.1906e-04,\n",
      "          1.3485e-03,  1.3785e-03,  9.9670e-04, -1.7766e-03,  1.5257e-03,\n",
      "         -2.0931e-03, -2.2499e-03,  1.4585e-03, -3.7782e-04, -2.4531e-03,\n",
      "         -1.2399e-03, -2.4878e-03, -1.8280e-03,  1.0347e-03, -8.6803e-04,\n",
      "          1.2663e-03, -2.2317e-03,  5.2472e-04, -8.1978e-04,  1.6563e-03,\n",
      "         -5.2744e-04,  6.4480e-06, -2.4227e-03, -1.8897e-04, -2.0841e-03,\n",
      "         -3.0500e-04,  1.1405e-03,  7.0273e-04, -1.3779e-03, -1.7033e-03,\n",
      "          1.2179e-03, -1.1364e-03,  2.0437e-04,  2.7947e-03,  1.7092e-03,\n",
      "          2.5460e-03, -2.4926e-03,  1.8131e-03,  6.6181e-04,  9.7978e-04,\n",
      "          1.9094e-03,  7.3825e-04,  1.1546e-03, -2.1648e-03,  2.6786e-03,\n",
      "         -1.1157e-03,  2.3455e-03, -1.2496e-03, -2.3353e-04, -2.0284e-03,\n",
      "          1.2923e-03, -2.0573e-03, -2.8572e-03, -1.6937e-03, -2.4323e-03,\n",
      "          2.2573e-03,  2.3935e-03, -1.0646e-03, -2.2616e-03,  1.8759e-03,\n",
      "         -1.6608e-03, -8.0217e-04,  2.8151e-03, -2.2408e-03, -2.9404e-03,\n",
      "          4.8485e-04,  1.3992e-03,  2.2419e-05,  9.8850e-04, -3.1122e-04,\n",
      "          1.3385e-03,  1.4438e-03, -9.5275e-04,  8.1534e-04, -7.2059e-04,\n",
      "         -6.8393e-04,  1.7183e-03, -1.8429e-04, -2.2234e-03,  2.6301e-03,\n",
      "         -3.3948e-04,  2.1223e-03, -2.0250e-03,  2.3345e-03, -8.4453e-04,\n",
      "          6.6008e-04, -1.3729e-04,  1.3717e-03, -1.4633e-03,  1.4186e-03]])), ('layers.1.bias', tensor([-0.0551]))])\n"
     ]
    }
   ],
   "source": [
    "# Actor model\n",
    "seed = 0\n",
    "actor = SimpleNeuralNetHead(action_size,\n",
    "                            SimpleNeuralNetBody(state_size, config[\"hidden_layers_actor\"], seed=seed),\n",
    "                            func=torch.tanh, seed=seed)\n",
    "# Critic model\n",
    "critic = DeepNeuralNetHeadCritic(action_size*num_agents,\n",
    "                                 SimpleNeuralNetBody(state_size*num_agents, config[\"hidden_layers_critic_body\"],\n",
    "                                                     func=eval(config[\"func_critic_body\"]), seed=seed),\n",
    "                                 hidden_layers_sizes=config[\"hidden_layers_critic_head\"],\n",
    "                                 func=eval(config[\"func_critic_head\"]),\n",
    "                                 end_func=None, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDPG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rllib.ddpgagent:Actor Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "INFO:rllib.ddpgagent:Critic Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "INFO:rllib.ddpgagent:Actor LR Scheduler: None\n",
      "INFO:rllib.ddpgagent:Critic LR Scheduler: None\n",
      "INFO:rllib.ddpgagent:Initiated state_normalizer=None, reward_normalizer=None\n"
     ]
    }
   ],
   "source": [
    "agent = MADDPGAgent(state_size=state_size, action_size=action_size,\n",
    "                    model_actor=actor, model_critic=critic,\n",
    "                    action_space_low=-1, action_space_high=1,\n",
    "                    config=config,\n",
    "                    )\n",
    "agent.debug_mode = False  # Current default debug_mode for agent is True, which would print out most variables \n",
    "for _agent in agent.agents: _agent.debug_mode = False\n",
    "# every 10000 steps of the agent. Turning off to not overwhelm the jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quentincangelosi/anaconda3/envs/rl/lib/python3.6/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "INFO:rllib.monitor:Episode 1    Average Score: 0.73, Agent Loss: [3.34303601e-02 4.31243749e-05], Last Score: avg=0.73, min=0.23, max=1.31 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 2    Average Score: 0.66, Agent Loss: [2.24504207e-02 2.91313480e-05], Last Score: avg=0.58, min=0.00, max=1.41 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 3    Average Score: 0.65, Agent Loss: [1.72723618e-02 2.50832856e-05], Last Score: avg=0.64, min=0.00, max=1.56 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 4    Average Score: 0.70, Agent Loss: [1.37112641e-02 2.47906114e-05], Last Score: avg=0.84, min=0.19, max=1.74 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 5    Average Score: 0.73, Agent Loss: [1.07426337e-02 2.57104234e-05], Last Score: avg=0.86, min=0.07, max=1.49 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 6    Average Score: 0.77, Agent Loss: [8.09020978e-03 2.71627240e-05], Last Score: avg=0.96, min=0.15, max=2.19 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 7    Average Score: 0.82, Agent Loss: [5.69422994e-03 2.92623652e-05], Last Score: avg=1.13, min=0.09, max=2.03 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 8    Average Score: 0.87, Agent Loss: [3.52537087e-03 3.17955376e-05], Last Score: avg=1.23, min=0.38, max=2.60 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 9    Average Score: 0.85, Agent Loss: [1.56865151e-03 3.50394739e-05], Last Score: avg=0.70, min=0.00, max=1.78 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 10    Average Score: 0.90, Agent Loss: [-2.15201590e-04  3.83514849e-05], Last Score: avg=1.35, min=0.35, max=2.49 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 11    Average Score: 0.97, Agent Loss: [-1.90435394e-03  4.20383367e-05], Last Score: avg=1.64, min=0.57, max=3.49 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 12    Average Score: 1.04, Agent Loss: [-3.49084933e-03  4.64235957e-05], Last Score: avg=1.83, min=0.20, max=3.09 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 13    Average Score: 1.16, Agent Loss: [-5.09777271e-03  5.19167131e-05], Last Score: avg=2.62, min=1.21, max=5.39 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 14    Average Score: 1.27, Agent Loss: [-6.75567950e-03  5.79768227e-05], Last Score: avg=2.66, min=1.03, max=4.57 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 15    Average Score: 1.38, Agent Loss: [-8.46685895e-03  6.45957676e-05], Last Score: avg=2.97, min=1.19, max=4.56 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 16    Average Score: 1.53, Agent Loss: [-1.02968759e-02  7.26866144e-05], Last Score: avg=3.79, min=1.73, max=6.20 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 17    Average Score: 1.68, Agent Loss: [-1.22460288e-02  8.14631321e-05], Last Score: avg=4.07, min=1.75, max=7.37 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 18    Average Score: 1.85, Agent Loss: [-1.43398851e-02  9.08330419e-05], Last Score: avg=4.62, min=1.46, max=7.06 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 19    Average Score: 2.00, Agent Loss: [-0.01653138  0.00010057], Last Score: avg=4.77, min=0.87, max=8.95 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 20    Average Score: 2.14, Agent Loss: [-0.0188454   0.00011081], Last Score: avg=4.82, min=2.72, max=8.58 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 21    Average Score: 2.30, Agent Loss: [-0.02126896  0.00012162], Last Score: avg=5.49, min=2.34, max=8.12 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 22    Average Score: 2.47, Agent Loss: [-0.02381752  0.00013282], Last Score: avg=5.95, min=3.55, max=8.43 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 23    Average Score: 2.69, Agent Loss: [-0.02650375  0.00014435], Last Score: avg=7.53, min=3.87, max=11.25 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 24    Average Score: 2.92, Agent Loss: [-0.02934504  0.00015714], Last Score: avg=8.38, min=3.81, max=15.67 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 25    Average Score: 3.13, Agent Loss: [-0.03236626  0.0001713 ], Last Score: avg=8.14, min=3.47, max=15.63 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:DDPG Agent: \n",
      "Actor Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Critic Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "INFO:rllib.monitor:Episode 26    Average Score: 3.39, Agent Loss: [-0.03560326  0.00018618], Last Score: avg=9.75, min=5.79, max=12.84 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 27    Average Score: 3.63, Agent Loss: [-0.03901781  0.00020179], Last Score: avg=9.97, min=6.29, max=15.52 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 28    Average Score: 3.86, Agent Loss: [-0.0426643   0.00021778], Last Score: avg=10.17, min=5.81, max=18.04 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 29    Average Score: 4.13, Agent Loss: [-0.04655319  0.0002347 ], Last Score: avg=11.48, min=8.49, max=14.93 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 30    Average Score: 4.39, Agent Loss: [-0.05064942  0.00025438], Last Score: avg=11.89, min=6.08, max=17.35 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 31    Average Score: 4.65, Agent Loss: [-0.05495399  0.00027479], Last Score: avg=12.61, min=8.07, max=19.73 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 32    Average Score: 5.00, Agent Loss: [-0.05952922  0.00029534], Last Score: avg=15.83, min=10.35, max=21.06 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 33    Average Score: 5.31, Agent Loss: [-0.06435618  0.00031739], Last Score: avg=15.35, min=11.59, max=20.38 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 34    Average Score: 5.59, Agent Loss: [-0.06945213  0.00033994], Last Score: avg=14.84, min=8.80, max=19.97 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 35    Average Score: 5.92, Agent Loss: [-0.07478407  0.000364  ], Last Score: avg=17.08, min=12.20, max=20.86 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 36    Average Score: 6.31, Agent Loss: [-0.08040951  0.00039012], Last Score: avg=20.04, min=14.64, max=25.88 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 37    Average Score: 6.73, Agent Loss: [-0.08633729  0.00041766], Last Score: avg=21.51, min=15.62, max=28.21 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 38    Average Score: 7.16, Agent Loss: [-0.09254767  0.00044648], Last Score: avg=23.27, min=13.80, max=27.08 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 39    Average Score: 7.62, Agent Loss: [-0.09904454  0.00047562], Last Score: avg=24.95, min=19.57, max=33.94 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 40    Average Score: 8.07, Agent Loss: [-0.10592473  0.00050747], Last Score: avg=25.54, min=6.11, max=31.88 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 41    Average Score: 8.56, Agent Loss: [-0.11318827  0.00053717], Last Score: avg=28.26, min=23.61, max=34.03 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 42    Average Score: 9.07, Agent Loss: [-0.1208161   0.00056981], Last Score: avg=30.10, min=24.52, max=33.72 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 43    Average Score: 9.52, Agent Loss: [-0.1287852   0.00060362], Last Score: avg=28.43, min=21.19, max=32.67 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 44    Average Score: 10.02, Agent Loss: [-0.137114    0.00063744], Last Score: avg=31.63, min=25.64, max=36.04 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 45    Average Score: 10.50, Agent Loss: [-0.14580165  0.00067603], Last Score: avg=31.45, min=23.93, max=37.93 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 46    Average Score: 10.96, Agent Loss: [-0.1548688   0.00071302], Last Score: avg=31.78, min=28.44, max=34.67 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 47    Average Score: 11.43, Agent Loss: [-0.16431047  0.0007526 ], Last Score: avg=33.18, min=27.02, max=37.31 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 48    Average Score: 11.92, Agent Loss: [-0.17412331  0.00079136], Last Score: avg=34.72, min=26.86, max=39.41 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 49    Average Score: 12.40, Agent Loss: [-0.18430636  0.00083063], Last Score: avg=35.66, min=31.98, max=38.64 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 50    Average Score: 12.88, Agent Loss: [-0.19487291  0.00087191], Last Score: avg=36.10, min=31.66, max=38.94 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:DDPG Agent: \n",
      "Actor Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Critic Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "INFO:rllib.monitor:Episode 51    Average Score: 13.34, Agent Loss: [-0.20587096  0.00091573], Last Score: avg=36.31, min=33.36, max=39.12 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 52    Average Score: 13.79, Agent Loss: [-0.21733915  0.00095675], Last Score: avg=37.03, min=31.97, max=39.55 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 53    Average Score: 14.24, Agent Loss: [-0.22926313  0.0009989 ], Last Score: avg=37.25, min=33.62, max=39.58 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 54    Average Score: 14.66, Agent Loss: [-0.24172892  0.0010481 ], Last Score: avg=36.91, min=34.01, max=38.87 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 55    Average Score: 15.07, Agent Loss: [-0.25463497  0.00109256], Last Score: avg=37.25, min=32.94, max=39.33 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 56    Average Score: 15.47, Agent Loss: [-0.26802155  0.00113587], Last Score: avg=37.62, min=35.28, max=39.53 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 57    Average Score: 15.86, Agent Loss: [-0.28179317  0.00118084], Last Score: avg=37.63, min=34.67, max=39.59 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 58    Average Score: 16.22, Agent Loss: [-0.29595801  0.00122986], Last Score: avg=37.12, min=33.20, max=38.63 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 59    Average Score: 16.58, Agent Loss: [-0.31049527  0.001275  ], Last Score: avg=37.19, min=35.20, max=39.14 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 60    Average Score: 16.92, Agent Loss: [-0.32541581  0.00132568], Last Score: avg=36.88, min=29.20, max=39.32 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 61    Average Score: 17.26, Agent Loss: [-0.34069607  0.00137433], Last Score: avg=37.65, min=34.68, max=39.58 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 62    Average Score: 17.57, Agent Loss: [-0.35629902  0.00142134], Last Score: avg=36.59, min=34.23, max=38.70 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 63    Average Score: 17.88, Agent Loss: [-0.37216133  0.00147128], Last Score: avg=37.25, min=34.46, max=39.20 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 64    Average Score: 18.19, Agent Loss: [-0.38827707  0.00151225], Last Score: avg=37.31, min=34.82, max=39.56 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 65    Average Score: 18.49, Agent Loss: [-0.40466504  0.00155677], Last Score: avg=37.92, min=35.87, max=39.49 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 66    Average Score: 18.79, Agent Loss: [-0.42132396  0.00160602], Last Score: avg=38.32, min=36.62, max=39.45 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 67    Average Score: 19.08, Agent Loss: [-0.43823208  0.0016534 ], Last Score: avg=37.88, min=35.51, max=39.48 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 68    Average Score: 19.35, Agent Loss: [-0.45526174  0.00170178], Last Score: avg=38.01, min=35.03, max=39.19 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 69    Average Score: 19.62, Agent Loss: [-0.47245425  0.001749  ], Last Score: avg=38.01, min=35.92, max=39.37 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 70    Average Score: 19.88, Agent Loss: [-0.48977829  0.00179417], Last Score: avg=37.88, min=35.44, max=39.63 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 71    Average Score: 20.14, Agent Loss: [-0.50724307  0.00184028], Last Score: avg=38.24, min=36.39, max=39.55 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 72    Average Score: 20.39, Agent Loss: [-0.52477519  0.00188494], Last Score: avg=37.71, min=35.41, max=39.35 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 73    Average Score: 20.63, Agent Loss: [-0.54237425  0.00192638], Last Score: avg=37.99, min=35.78, max=39.53 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 74    Average Score: 20.86, Agent Loss: [-0.56002475  0.00196783], Last Score: avg=37.60, min=35.20, max=39.58 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 75    Average Score: 21.08, Agent Loss: [-0.57771465  0.00201693], Last Score: avg=37.61, min=33.31, max=39.21 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:DDPG Agent: \n",
      "Actor Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Critic Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "INFO:rllib.monitor:Episode 76    Average Score: 21.29, Agent Loss: [-0.59540631  0.00205729], Last Score: avg=37.21, min=34.25, max=39.30 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 77    Average Score: 21.51, Agent Loss: [-0.61310978  0.00209579], Last Score: avg=38.22, min=33.37, max=39.60 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 78    Average Score: 21.73, Agent Loss: [-0.63080089  0.00213717], Last Score: avg=38.39, min=36.40, max=39.60 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 79    Average Score: 21.92, Agent Loss: [-0.64844473  0.00217833], Last Score: avg=36.38, min=31.24, max=39.62 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 80    Average Score: 22.10, Agent Loss: [-0.66608229  0.00222058], Last Score: avg=37.00, min=33.63, max=39.45 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 81    Average Score: 22.28, Agent Loss: [-0.68366094  0.00227245], Last Score: avg=36.14, min=33.35, max=39.01 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 82    Average Score: 22.46, Agent Loss: [-0.70118289  0.0023155 ], Last Score: avg=37.38, min=32.31, max=39.49 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 83    Average Score: 22.64, Agent Loss: [-0.71864676  0.00234282], Last Score: avg=37.56, min=33.22, max=39.27 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 84    Average Score: 22.81, Agent Loss: [-0.73602631  0.00238061], Last Score: avg=36.40, min=29.13, max=39.02 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 85    Average Score: 22.96, Agent Loss: [-0.75331158  0.00242069], Last Score: avg=35.96, min=27.46, max=38.30 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 86    Average Score: 23.13, Agent Loss: [-0.77050885  0.00245586], Last Score: avg=37.15, min=31.43, max=39.34 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 87    Average Score: 23.28, Agent Loss: [-0.78760682  0.0024889 ], Last Score: avg=36.91, min=31.22, max=39.62 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 88    Average Score: 23.44, Agent Loss: [-0.80457291  0.00252352], Last Score: avg=37.11, min=34.35, max=39.61 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 89    Average Score: 23.60, Agent Loss: [-0.82140856  0.0025757 ], Last Score: avg=37.73, min=32.70, max=38.71 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 90    Average Score: 23.73, Agent Loss: [-0.83810143  0.00262196], Last Score: avg=35.23, min=30.24, max=38.89 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 91    Average Score: 23.84, Agent Loss: [-0.85461489  0.00267469], Last Score: avg=33.66, min=25.21, max=38.64 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 92    Average Score: 23.98, Agent Loss: [-0.8709543   0.00272377], Last Score: avg=36.20, min=33.57, max=38.43 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 93    Average Score: 24.09, Agent Loss: [-0.887165    0.00276091], Last Score: avg=35.00, min=30.63, max=38.83 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 94    Average Score: 24.19, Agent Loss: [-0.90322926  0.00280325], Last Score: avg=32.98, min=25.65, max=38.31 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 95    Average Score: 24.31, Agent Loss: [-0.91914338  0.00285224], Last Score: avg=35.97, min=31.94, max=37.94 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 96    Average Score: 24.44, Agent Loss: [-0.93492327  0.00289247], Last Score: avg=36.76, min=33.96, max=39.19 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 97    Average Score: 24.53, Agent Loss: [-0.95054698  0.00293795], Last Score: avg=33.25, min=29.19, max=38.42 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 98    Average Score: 24.63, Agent Loss: [-0.96602541  0.00297875], Last Score: avg=34.36, min=28.38, max=39.29 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 99    Average Score: 24.76, Agent Loss: [-0.98136165  0.00301405], Last Score: avg=37.07, min=29.24, max=39.37 (1000 steps), eps: 1.00\n",
      "/Users/quentincangelosi/anaconda3/envs/rl/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/quentincangelosi/anaconda3/envs/rl/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "INFO:rllib.monitor:Episode 100    Average Score: 24.87, Agent Loss: nan, Last Score: avg=35.56, min=31.95, max=38.82 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:DDPG Agent: \n",
      "Actor Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Critic Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "INFO:rllib.monitor:Saving model to ./results/MultiAgents_DDPG_1605629419707226000\n",
      "INFO:rllib.monitor:Episode 101    Average Score: 25.22, Agent Loss: [3.34303601e-02 4.31243749e-05], Last Score: avg=35.62, min=31.51, max=38.50 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 102    Average Score: 25.57, Agent Loss: [2.24504207e-02 2.91313480e-05], Last Score: avg=35.67, min=29.96, max=38.81 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 103    Average Score: 25.93, Agent Loss: [1.72723618e-02 2.50832856e-05], Last Score: avg=36.53, min=30.70, max=39.11 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 104    Average Score: 26.27, Agent Loss: [1.37112641e-02 2.47906114e-05], Last Score: avg=35.45, min=32.05, max=38.83 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 105    Average Score: 26.63, Agent Loss: [1.07426337e-02 2.57104234e-05], Last Score: avg=36.52, min=34.44, max=38.37 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 106    Average Score: 26.98, Agent Loss: [8.09020978e-03 2.71627240e-05], Last Score: avg=36.03, min=32.05, max=38.59 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 107    Average Score: 27.32, Agent Loss: [5.69422994e-03 2.92623652e-05], Last Score: avg=35.03, min=31.41, max=38.18 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 108    Average Score: 27.62, Agent Loss: [3.52537087e-03 3.17955376e-05], Last Score: avg=30.99, min=25.26, max=37.25 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 109    Average Score: 27.95, Agent Loss: [1.56865151e-03 3.50394739e-05], Last Score: avg=34.09, min=27.75, max=37.90 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 110    Average Score: 28.26, Agent Loss: [-2.15201590e-04  3.83514849e-05], Last Score: avg=32.87, min=28.01, max=36.96 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 111    Average Score: 28.60, Agent Loss: [-1.90435394e-03  4.20383367e-05], Last Score: avg=35.68, min=32.87, max=38.61 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 112    Average Score: 28.93, Agent Loss: [-3.49084933e-03  4.64235957e-05], Last Score: avg=34.31, min=30.69, max=37.34 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 113    Average Score: 29.26, Agent Loss: [-5.09777271e-03  5.19167131e-05], Last Score: avg=35.78, min=32.34, max=38.92 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 114    Average Score: 29.59, Agent Loss: [-6.75567950e-03  5.79768227e-05], Last Score: avg=35.59, min=25.81, max=38.30 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 115    Average Score: 29.90, Agent Loss: [-8.46685895e-03  6.45957676e-05], Last Score: avg=34.37, min=31.19, max=39.11 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 116    Average Score: 30.22, Agent Loss: [-1.02968759e-02  7.26866144e-05], Last Score: avg=35.27, min=27.35, max=39.36 (1000 steps), eps: 1.00\n",
      "WARNING:rllib.monitor:\n",
      "Environment solved in 116 episodes!\tAverage Score: 30.22\n",
      "INFO:rllib.monitor:Episode 117    Average Score: 30.54, Agent Loss: [-1.22460288e-02  8.14631321e-05], Last Score: avg=35.90, min=29.86, max=38.43 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 118    Average Score: 30.85, Agent Loss: [-1.43398851e-02  9.08330419e-05], Last Score: avg=36.10, min=32.62, max=39.28 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 119    Average Score: 31.17, Agent Loss: [-0.01653138  0.00010057], Last Score: avg=36.31, min=32.53, max=38.96 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 120    Average Score: 31.48, Agent Loss: [-0.0188454   0.00011081], Last Score: avg=36.12, min=28.33, max=38.89 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 121    Average Score: 31.78, Agent Loss: [-0.02126896  0.00012162], Last Score: avg=35.85, min=33.04, max=38.98 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 122    Average Score: 32.09, Agent Loss: [-0.02381752  0.00013282], Last Score: avg=36.82, min=34.57, max=38.59 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 123    Average Score: 32.38, Agent Loss: [-0.02650375  0.00014435], Last Score: avg=35.88, min=30.81, max=39.35 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 124    Average Score: 32.66, Agent Loss: [-0.02934504  0.00015714], Last Score: avg=36.70, min=33.34, max=38.24 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 125    Average Score: 32.93, Agent Loss: [-0.03236626  0.0001713 ], Last Score: avg=35.62, min=27.57, max=38.40 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:DDPG Agent: \n",
      "Actor Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Critic Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "INFO:rllib.monitor:Episode 126    Average Score: 33.18, Agent Loss: [-0.03560326  0.00018618], Last Score: avg=34.47, min=29.07, max=37.80 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 127    Average Score: 33.45, Agent Loss: [-0.03901781  0.00020179], Last Score: avg=36.90, min=33.56, max=39.03 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 128    Average Score: 33.71, Agent Loss: [-0.0426643   0.00021778], Last Score: avg=35.81, min=32.02, max=38.58 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 129    Average Score: 33.96, Agent Loss: [-0.04655319  0.0002347 ], Last Score: avg=36.96, min=34.69, max=38.78 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 130    Average Score: 34.21, Agent Loss: [-0.05064942  0.00025438], Last Score: avg=36.50, min=34.01, max=38.97 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 131    Average Score: 34.45, Agent Loss: [-0.05495399  0.00027479], Last Score: avg=36.96, min=34.91, max=38.83 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 132    Average Score: 34.64, Agent Loss: [-0.05952922  0.00029534], Last Score: avg=34.30, min=31.72, max=37.90 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 133    Average Score: 34.83, Agent Loss: [-0.06435618  0.00031739], Last Score: avg=34.64, min=32.43, max=36.98 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 134    Average Score: 35.04, Agent Loss: [-0.06945213  0.00033994], Last Score: avg=36.14, min=31.95, max=38.17 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 135    Average Score: 35.22, Agent Loss: [-0.07478407  0.000364  ], Last Score: avg=34.83, min=30.77, max=36.99 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 136    Average Score: 35.36, Agent Loss: [-0.08040951  0.00039012], Last Score: avg=34.41, min=31.08, max=37.81 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 137    Average Score: 35.50, Agent Loss: [-0.08633729  0.00041766], Last Score: avg=35.58, min=31.71, max=37.83 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 138    Average Score: 35.62, Agent Loss: [-0.09254767  0.00044648], Last Score: avg=34.36, min=30.70, max=37.93 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 139    Average Score: 35.72, Agent Loss: [-0.09904454  0.00047562], Last Score: avg=35.88, min=32.17, max=38.25 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 140    Average Score: 35.83, Agent Loss: [-0.10592473  0.00050747], Last Score: avg=35.92, min=32.09, max=38.75 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 141    Average Score: 35.91, Agent Loss: [-0.11318827  0.00053717], Last Score: avg=36.87, min=29.57, max=39.60 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 142    Average Score: 35.98, Agent Loss: [-0.1208161   0.00056981], Last Score: avg=36.66, min=32.97, max=38.60 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 143    Average Score: 36.05, Agent Loss: [-0.1287852   0.00060362], Last Score: avg=35.54, min=29.86, max=38.95 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 144    Average Score: 36.10, Agent Loss: [-0.137114    0.00063744], Last Score: avg=36.46, min=33.89, max=38.65 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 145    Average Score: 36.15, Agent Loss: [-0.14580165  0.00067603], Last Score: avg=36.94, min=33.93, max=38.83 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 146    Average Score: 36.20, Agent Loss: [-0.1548688   0.00071302], Last Score: avg=36.71, min=32.23, max=38.82 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 147    Average Score: 36.24, Agent Loss: [-0.16431047  0.0007526 ], Last Score: avg=37.18, min=33.60, max=39.43 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 148    Average Score: 36.27, Agent Loss: [-0.17412331  0.00079136], Last Score: avg=37.38, min=34.02, max=39.15 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 149    Average Score: 36.28, Agent Loss: [-0.18430636  0.00083063], Last Score: avg=36.54, min=33.42, max=39.54 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 150    Average Score: 36.28, Agent Loss: [-0.19487291  0.00087191], Last Score: avg=35.75, min=31.19, max=37.96 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:DDPG Agent: \n",
      "Actor Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Critic Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "INFO:rllib.monitor:Episode 151    Average Score: 36.28, Agent Loss: [-0.20587096  0.00091573], Last Score: avg=36.61, min=33.24, max=39.35 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 152    Average Score: 36.28, Agent Loss: [-0.21733915  0.00095675], Last Score: avg=37.11, min=34.42, max=39.48 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 153    Average Score: 36.26, Agent Loss: [-0.22926313  0.0009989 ], Last Score: avg=35.72, min=31.63, max=38.60 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 154    Average Score: 36.26, Agent Loss: [-0.24172892  0.0010481 ], Last Score: avg=36.72, min=34.73, max=39.23 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 155    Average Score: 36.26, Agent Loss: [-0.25463497  0.00109256], Last Score: avg=36.60, min=32.49, max=38.59 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 156    Average Score: 36.24, Agent Loss: [-0.26802155  0.00113587], Last Score: avg=36.34, min=33.30, max=38.71 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 157    Average Score: 36.22, Agent Loss: [-0.28179317  0.00118084], Last Score: avg=35.50, min=31.67, max=37.38 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 158    Average Score: 36.21, Agent Loss: [-0.29595801  0.00122986], Last Score: avg=35.90, min=32.02, max=38.65 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 159    Average Score: 36.19, Agent Loss: [-0.31049527  0.001275  ], Last Score: avg=35.02, min=33.07, max=38.07 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 160    Average Score: 36.17, Agent Loss: [-0.32541581  0.00132568], Last Score: avg=35.49, min=30.67, max=38.89 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 161    Average Score: 36.16, Agent Loss: [-0.34069607  0.00137433], Last Score: avg=35.87, min=31.43, max=38.97 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 162    Average Score: 36.13, Agent Loss: [-0.35629902  0.00142134], Last Score: avg=34.26, min=26.05, max=37.35 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 163    Average Score: 36.12, Agent Loss: [-0.37216133  0.00147128], Last Score: avg=36.43, min=33.53, max=38.15 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 164    Average Score: 36.10, Agent Loss: [-0.38827707  0.00151225], Last Score: avg=34.67, min=30.99, max=37.50 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 165    Average Score: 36.08, Agent Loss: [-0.40466504  0.00155677], Last Score: avg=36.00, min=31.63, max=38.56 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 166    Average Score: 36.06, Agent Loss: [-0.42132396  0.00160602], Last Score: avg=36.31, min=32.07, max=38.70 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 167    Average Score: 36.01, Agent Loss: [-0.43823208  0.0016534 ], Last Score: avg=33.19, min=26.87, max=37.48 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 168    Average Score: 35.99, Agent Loss: [-0.45526174  0.00170178], Last Score: avg=36.08, min=33.10, max=39.29 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 169    Average Score: 35.97, Agent Loss: [-0.47245425  0.001749  ], Last Score: avg=35.65, min=32.29, max=37.90 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 170    Average Score: 35.96, Agent Loss: [-0.48977829  0.00179417], Last Score: avg=36.81, min=31.68, max=39.37 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 171    Average Score: 35.92, Agent Loss: [-0.50724307  0.00184028], Last Score: avg=34.61, min=29.84, max=37.68 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 172    Average Score: 35.88, Agent Loss: [-0.52477519  0.00188494], Last Score: avg=33.63, min=29.12, max=36.57 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 173    Average Score: 35.85, Agent Loss: [-0.54237425  0.00192638], Last Score: avg=34.63, min=30.82, max=37.35 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 174    Average Score: 35.83, Agent Loss: [-0.56002475  0.00196783], Last Score: avg=35.37, min=32.35, max=38.58 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 175    Average Score: 35.79, Agent Loss: [-0.57771465  0.00201693], Last Score: avg=34.17, min=29.67, max=37.79 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:DDPG Agent: \n",
      "Actor Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Critic Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "INFO:rllib.monitor:Episode 176    Average Score: 35.78, Agent Loss: [-0.59540631  0.00205729], Last Score: avg=35.65, min=31.83, max=38.59 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 177    Average Score: 35.75, Agent Loss: [-0.61310978  0.00209579], Last Score: avg=35.34, min=31.95, max=38.47 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 178    Average Score: 35.69, Agent Loss: [-0.63080089  0.00213717], Last Score: avg=32.29, min=28.85, max=35.25 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 179    Average Score: 35.66, Agent Loss: [-0.64844473  0.00217833], Last Score: avg=33.88, min=30.35, max=38.01 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 180    Average Score: 35.64, Agent Loss: [-0.66608229  0.00222058], Last Score: avg=35.28, min=32.40, max=38.17 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 181    Average Score: 35.65, Agent Loss: [-0.68366094  0.00227245], Last Score: avg=37.09, min=32.91, max=39.53 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 182    Average Score: 35.64, Agent Loss: [-0.70118289  0.0023155 ], Last Score: avg=36.39, min=31.97, max=38.77 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 183    Average Score: 35.63, Agent Loss: [-0.71864676  0.00234282], Last Score: avg=36.03, min=33.79, max=38.89 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 184    Average Score: 35.63, Agent Loss: [-0.73602631  0.00238061], Last Score: avg=36.23, min=33.39, max=38.66 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 185    Average Score: 35.63, Agent Loss: [-0.75331158  0.00242069], Last Score: avg=36.59, min=34.13, max=38.82 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 186    Average Score: 35.62, Agent Loss: [-0.77050885  0.00245586], Last Score: avg=36.14, min=33.56, max=38.25 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 187    Average Score: 35.61, Agent Loss: [-0.78760682  0.0024889 ], Last Score: avg=36.13, min=32.63, max=38.45 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 188    Average Score: 35.60, Agent Loss: [-0.80457291  0.00252352], Last Score: avg=35.30, min=30.46, max=37.73 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 189    Average Score: 35.58, Agent Loss: [-0.82140856  0.0025757 ], Last Score: avg=36.57, min=31.86, max=39.18 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 190    Average Score: 35.60, Agent Loss: [-0.83810143  0.00262196], Last Score: avg=36.37, min=33.24, max=39.32 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 191    Average Score: 35.61, Agent Loss: [-0.85461489  0.00267469], Last Score: avg=35.06, min=29.59, max=38.68 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 192    Average Score: 35.62, Agent Loss: [-0.8709543   0.00272377], Last Score: avg=37.11, min=35.59, max=38.59 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 193    Average Score: 35.64, Agent Loss: [-0.887165    0.00276091], Last Score: avg=37.17, min=33.70, max=39.11 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 194    Average Score: 35.67, Agent Loss: [-0.90322926  0.00280325], Last Score: avg=35.80, min=32.11, max=38.51 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 195    Average Score: 35.67, Agent Loss: [-0.91914338  0.00285224], Last Score: avg=35.83, min=30.96, max=38.82 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 196    Average Score: 35.64, Agent Loss: [-0.93492327  0.00289247], Last Score: avg=33.96, min=26.59, max=37.60 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 197    Average Score: 35.66, Agent Loss: [-0.95054698  0.00293795], Last Score: avg=35.53, min=33.15, max=37.48 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 198    Average Score: 35.68, Agent Loss: [-0.96602541  0.00297875], Last Score: avg=36.12, min=32.29, max=38.53 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 199    Average Score: 35.65, Agent Loss: [-0.98136165  0.00301405], Last Score: avg=34.13, min=27.55, max=37.67 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 200    Average Score: 35.64, Agent Loss: [-0.99655342  0.00305422], Last Score: avg=34.46, min=31.04, max=38.92 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:DDPG Agent: \n",
      "Actor Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Critic Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "INFO:rllib.monitor:Saving model to ./results/MultiAgents_DDPG_1605629419707226000\n",
      "INFO:rllib.monitor:Episode 201    Average Score: 35.62, Agent Loss: [-1.01159684  0.00308976], Last Score: avg=34.11, min=31.17, max=38.00 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 202    Average Score: 35.61, Agent Loss: [-1.02649492  0.00311939], Last Score: avg=33.71, min=30.91, max=36.56 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 203    Average Score: 35.59, Agent Loss: [-1.04125396  0.00315143], Last Score: avg=34.72, min=31.76, max=38.10 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 204    Average Score: 35.58, Agent Loss: [-1.05588889  0.00318939], Last Score: avg=35.23, min=31.43, max=38.49 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 205    Average Score: 35.58, Agent Loss: [-1.07037897  0.00323104], Last Score: avg=35.71, min=31.78, max=38.60 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 206    Average Score: 35.56, Agent Loss: [-1.08472545  0.00348356], Last Score: avg=34.04, min=29.49, max=37.72 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 207    Average Score: 35.57, Agent Loss: [-1.09891094  0.00382291], Last Score: avg=35.88, min=32.17, max=38.48 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 208    Average Score: 35.61, Agent Loss: [-1.11296555  0.00385428], Last Score: avg=35.71, min=29.37, max=38.68 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 209    Average Score: 35.64, Agent Loss: [-1.12687949  0.003892  ], Last Score: avg=36.60, min=33.12, max=38.89 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 210    Average Score: 35.68, Agent Loss: [-1.14066526  0.00392474], Last Score: avg=36.95, min=34.09, max=39.02 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 211    Average Score: 35.69, Agent Loss: [-1.15433144  0.00396584], Last Score: avg=36.45, min=34.21, max=39.66 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 212    Average Score: 35.71, Agent Loss: [-1.16786816  0.00399969], Last Score: avg=36.97, min=33.23, max=39.31 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 213    Average Score: 35.71, Agent Loss: [-1.18128079  0.0040289 ], Last Score: avg=35.06, min=29.01, max=38.29 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 214    Average Score: 35.70, Agent Loss: [-1.19457613  0.00406275], Last Score: avg=35.36, min=30.09, max=38.64 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 215    Average Score: 35.72, Agent Loss: [-1.20775606  0.00409235], Last Score: avg=36.24, min=33.99, max=38.53 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 216    Average Score: 35.74, Agent Loss: [-1.22081116  0.00412403], Last Score: avg=37.11, min=32.26, max=38.74 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 217    Average Score: 35.73, Agent Loss: [-1.23373555  0.00415578], Last Score: avg=35.30, min=32.97, max=37.73 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 218    Average Score: 35.73, Agent Loss: [-1.24655201  0.00418066], Last Score: avg=35.56, min=32.02, max=37.38 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 219    Average Score: 35.71, Agent Loss: [-1.25925375  0.00421477], Last Score: avg=34.94, min=26.91, max=38.54 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 220    Average Score: 35.71, Agent Loss: [-1.27183461  0.00424896], Last Score: avg=35.53, min=30.35, max=38.08 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 221    Average Score: 35.70, Agent Loss: [-1.28429795  0.00428991], Last Score: avg=35.15, min=31.92, max=37.45 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 222    Average Score: 35.67, Agent Loss: [-1.29662588  0.00431997], Last Score: avg=33.25, min=28.97, max=35.55 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 223    Average Score: 35.65, Agent Loss: [-1.30885317  0.00434829], Last Score: avg=34.05, min=28.84, max=37.97 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 224    Average Score: 35.63, Agent Loss: [-1.32096206  0.0043879 ], Last Score: avg=35.24, min=31.32, max=37.79 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 225    Average Score: 35.64, Agent Loss: [-1.33295764  0.00441813], Last Score: avg=35.78, min=31.90, max=37.86 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:DDPG Agent: \n",
      "Actor Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Critic Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "INFO:rllib.monitor:Episode 226    Average Score: 35.62, Agent Loss: [-1.34485119  0.00444787], Last Score: avg=33.00, min=28.50, max=35.99 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 227    Average Score: 35.59, Agent Loss: [-1.35663905  0.00447967], Last Score: avg=34.04, min=29.67, max=36.69 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 228    Average Score: 35.58, Agent Loss: [-1.36831333  0.00451784], Last Score: avg=34.19, min=29.60, max=36.84 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 229    Average Score: 35.54, Agent Loss: [-1.37988769  0.00455024], Last Score: avg=32.91, min=26.43, max=37.72 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 230    Average Score: 35.52, Agent Loss: [-1.391369   0.0045737], Last Score: avg=35.32, min=30.20, max=37.92 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 231    Average Score: 35.50, Agent Loss: [-1.40275041  0.00460538], Last Score: avg=34.82, min=28.61, max=39.08 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 232    Average Score: 35.52, Agent Loss: [-1.41404651  0.00464681], Last Score: avg=36.25, min=30.05, max=39.29 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 233    Average Score: 35.51, Agent Loss: [-1.42522828  0.00469038], Last Score: avg=33.95, min=23.67, max=38.32 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 234    Average Score: 35.46, Agent Loss: [-1.43630684  0.00472988], Last Score: avg=30.97, min=26.50, max=34.88 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 235    Average Score: 35.44, Agent Loss: [-1.44729645  0.00476251], Last Score: avg=32.46, min=27.90, max=36.15 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 236    Average Score: 35.43, Agent Loss: [-1.45819211  0.00480165], Last Score: avg=33.75, min=30.15, max=36.29 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 237    Average Score: 35.43, Agent Loss: [-1.46899357  0.00483542], Last Score: avg=35.62, min=32.80, max=38.99 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 238    Average Score: 35.45, Agent Loss: [-1.47971675  0.00485899], Last Score: avg=36.40, min=32.03, max=38.80 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 239    Average Score: 35.44, Agent Loss: [-1.49036323  0.00489279], Last Score: avg=34.65, min=29.89, max=37.72 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 240    Average Score: 35.44, Agent Loss: [-1.50093678  0.00491366], Last Score: avg=35.34, min=31.62, max=37.73 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 241    Average Score: 35.43, Agent Loss: [-1.51146535  0.00494785], Last Score: avg=36.23, min=32.98, max=38.20 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 242    Average Score: 35.42, Agent Loss: [-1.52192656  0.00498438], Last Score: avg=35.31, min=31.37, max=37.62 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 243    Average Score: 35.41, Agent Loss: [-1.53232985  0.00501522], Last Score: avg=34.85, min=31.30, max=37.17 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 244    Average Score: 35.41, Agent Loss: [-1.54265267  0.00505236], Last Score: avg=36.17, min=33.18, max=38.26 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 245    Average Score: 35.39, Agent Loss: [-1.55291323  0.00508017], Last Score: avg=35.37, min=31.20, max=38.52 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 246    Average Score: 35.36, Agent Loss: [-1.56309785  0.00511701], Last Score: avg=33.39, min=27.14, max=37.37 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 247    Average Score: 35.34, Agent Loss: [-1.57322092  0.00514232], Last Score: avg=35.09, min=31.40, max=37.44 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 248    Average Score: 35.29, Agent Loss: [-1.58327054  0.00517813], Last Score: avg=32.43, min=27.79, max=37.87 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 249    Average Score: 35.27, Agent Loss: [-1.5932383   0.00521222], Last Score: avg=34.75, min=30.02, max=38.35 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:Episode 250    Average Score: 35.26, Agent Loss: [-1.6031334   0.00524621], Last Score: avg=34.65, min=28.36, max=38.01 (1000 steps), eps: 1.00\n",
      "INFO:rllib.monitor:DDPG Agent: \n",
      "Actor Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Critic Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "INFO:rllib.monitor:Saving model to ./results/MultiAgents_DDPG_1605629419707226000\n",
      "INFO:rllib.monitor:Elapsed Time: 0 days 01:54:10.993063\n",
      "INFO:root:Average Score last 100 episodes: 35.25763921193033\n",
      "INFO:root:Elapsed Time: 6850.999889 seconds\n"
     ]
    }
   ],
   "source": [
    "start = pd.Timestamp.utcnow()\n",
    "scores = monitor.run(agent)\n",
    "logger.info(\"Average Score last 100 episodes: {}\".format(np.mean(scores[-100:])))\n",
    "elapsed_time = pd.Timedelta(pd.Timestamp.utcnow() - start).total_seconds()\n",
    "logger.info(f\"Elapsed Time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "sb.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "sb.despine()\n",
    "sb.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12c6b3f60>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "df = pd.DataFrame({\"scores\": np.mean(scores, axis=1)})\n",
    "df[\"episode\"] = df.index + 1\n",
    "df[\"rolling_score_100\"] = df[\"scores\"].rolling(100).mean()\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "sb.lineplot(x=\"episode\", y=\"scores\", data=df)\n",
    "sb.lineplot(x=\"episode\", y=\"rolling_score_100\", data=df)\n",
    "plt.axhline(0.5, c=\"r\", ls=\"--\", label=\"Objective: 0.5\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rllib.models:Initialized SimpleNeuralNetHead with body : ModuleList(\n",
      "  (0): Linear(in_features=24, out_features=256, bias=True)\n",
      "  (1): Linear(in_features=256, out_features=128, bias=True)\n",
      ") and head Linear(in_features=128, out_features=2, bias=True)\n",
      "INFO:rllib.models:Initialized DeepNeuralNetHeadCritic with body : ModuleList(\n",
      "  (0): Linear(in_features=48, out_features=256, bias=True)\n",
      ") and head ModuleList(\n",
      "  (0): Linear(in_features=260, out_features=128, bias=True)\n",
      "  (1): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "INFO:rllib.ddpgagent:Actor Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "INFO:rllib.ddpgagent:Critic Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "INFO:rllib.ddpgagent:Actor LR Scheduler: None\n",
      "INFO:rllib.ddpgagent:Critic LR Scheduler: None\n",
      "INFO:rllib.ddpgagent:Initiated state_normalizer=None, reward_normalizer=None\n",
      "INFO:rllib.ddpgagent:Loading Agent from ./agent_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.69487906 -1.5\n",
      " -0.          0.          6.83172083  5.98822832 -0.          0.        ]\n"
     ]
    },
    {
     "ename": "UnityActionException",
     "evalue": "There was a mismatch between the provided action and environment's expectation: The brain TennisBrain expected 4 continuous action(s), but was provided: [0.3528104691935328, 0.08003144167344467]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityActionException\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-421de85cee7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Score over {len(scores)} episodes: {np.mean(scores)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/5. Other/2. DataScience/github/RL-Library/rl_library/monitors/base_monitor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, agent)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;31m#print(f\"\\rAction: {action} Processed: {self.process_action(action)}\", end=\"\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# send the action to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0;31m# last_actions.append(action)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;31m# last_states.append(state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/5. Other/2. DataScience/github/RL-Library/rl_library/monitors/unity_monitor.py\u001b[0m in \u001b[0;36menv_step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0menv_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# send the action to the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m \u001b[0;31m# get the next state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m  \u001b[0;31m# get the reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/rl/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, vector_action, memory, text_action)\u001b[0m\n\u001b[1;32m    364\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_brains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_action_space_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_brains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_action_space_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m                         str(vector_action[b])))\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             outputs = self.communicator.exchange(\n",
      "\u001b[0;31mUnityActionException\u001b[0m: There was a mismatch between the provided action and environment's expectation: The brain TennisBrain expected 4 continuous action(s), but was provided: [0.3528104691935328, 0.08003144167344467]"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(f\"./config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config[\"mode\"] = \"test\"\n",
    "config[\"n_episodes\"] = 10\n",
    "\n",
    "monitor = UnityMonitor(env=env, config=config)\n",
    "# Actor model\n",
    "seed = 0\n",
    "actor = SimpleNeuralNetHead(action_size,\n",
    "                            SimpleNeuralNetBody(state_size, config[\"hidden_layers_actor\"], seed=seed),\n",
    "                            func=torch.tanh, seed=seed)\n",
    "# Critic model\n",
    "critic = DeepNeuralNetHeadCritic(action_size*num_agents,\n",
    "                                 SimpleNeuralNetBody(state_size*num_agents, config[\"hidden_layers_critic_body\"],\n",
    "                                                     func=eval(config[\"func_critic_body\"]), seed=seed),\n",
    "                                 hidden_layers_sizes=config[\"hidden_layers_critic_head\"],\n",
    "                                 func=eval(config[\"func_critic_head\"]),\n",
    "                                 end_func=None, seed=seed)\n",
    "\n",
    "# MADDPG Agent\n",
    "agent = MADDPGAgent(state_size=state_size, action_size=action_size,\n",
    "                    model_actor=actor, model_critic=critic,\n",
    "                    action_space_low=-1, action_space_high=1,\n",
    "                    config=config,\n",
    "                    )\n",
    "agent.load(\".\")\n",
    "agent.debug_mode = False\n",
    "env.reset(train_mode=False)[brain_name]\n",
    "scores = monitor.run(agent)\n",
    "\n",
    "logger.info(f\"Test Score over {len(scores)} episodes: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Closing...\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Closing...\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
